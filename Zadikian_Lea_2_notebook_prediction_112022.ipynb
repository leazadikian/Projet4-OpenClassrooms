{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee400ca",
   "metadata": {},
   "source": [
    "Léa ZADIKIAN - Novembre 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3a0a5",
   "metadata": {},
   "source": [
    "# Projet n°4 : Anticipez les besoins en consommation de bâtiments\n",
    "# Notebook prédiction de la consommation d'énergie\n",
    "La prédiction des émissions est réalisée dans un Notebook séparé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a448f1",
   "metadata": {},
   "source": [
    "Données et définition des variables : https://data.seattle.gov/dataset/2016-Building-Energy-Benchmarking/2bpz-gwpy\n",
    "\n",
    "**Objectif** : prédire les émissions de CO2 et la consommation totale d’énergie de bâtiments non destinés à l’habitation de la ville de Seattle, pour lesquels elles n’ont pas encore été mesurées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a656425",
   "metadata": {},
   "source": [
    "# Sommaire :\n",
    "\n",
    "<a href=\"#C1\">1. Première itération</a>\n",
    "\n",
    "1.1 Import et préparation des données\n",
    "- Importation du jeu de données cleanné\n",
    "- Préparation des données : standardisation, séparation jeu de d'entraînement / jeu de test\n",
    "\n",
    "1.2 Approche naïve : Dummy regressor\n",
    "    \n",
    "1.3 Modèle linéaire : Elastic Net\n",
    "    \n",
    "1.4. Modèle non linéaire : Random Forest\n",
    "    \n",
    "<a href=\"#C2\">2.Deuxième itération </a>\n",
    "\n",
    "2.1 Import et préparation des données\n",
    "\n",
    "2.2 Approche naïve : Dummy regressor\n",
    "\n",
    "2.3 Modèle linéaire : Elastic Net\n",
    "\n",
    "2.4 Modèle non linéaire : Random Forest\n",
    "\n",
    "<a href=\"#C3\">3.Troisième itération : intérêt de ENERGYSTAR Score</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f856ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import kernel_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c01c2",
   "metadata": {},
   "source": [
    "# <a name=\"C1\">1. Première itération </a>\n",
    "## 1.1 Import et préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1e335",
   "metadata": {},
   "source": [
    "### 1.1.1 Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335b796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>log_TotalGHGEmissions</th>\n",
       "      <th>log_SiteEnergyUse(kBtu)</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_1920's</th>\n",
       "      <th>x3_1930's</th>\n",
       "      <th>x3_1940's</th>\n",
       "      <th>x3_1950's</th>\n",
       "      <th>x3_1960's</th>\n",
       "      <th>x3_1970's</th>\n",
       "      <th>x3_1980's</th>\n",
       "      <th>x3_1990's</th>\n",
       "      <th>x3_2000's</th>\n",
       "      <th>x3_2010's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.971429</td>\n",
       "      <td>22.784838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>8.213639</td>\n",
       "      <td>22.999884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>11.029480</td>\n",
       "      <td>26.113208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.167067</td>\n",
       "      <td>22.695954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>8.983022</td>\n",
       "      <td>23.756602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.414812</td>\n",
       "      <td>19.830099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.051807</td>\n",
       "      <td>19.857989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.810829</td>\n",
       "      <td>22.459114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.530445</td>\n",
       "      <td>19.456579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.401562</td>\n",
       "      <td>20.136833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  log_TotalGHGEmissions  log_SiteEnergyUse(kBtu)  \\\n",
       "0                   0.000000               7.971429                22.784838   \n",
       "1                  13.878913               8.213639                22.999884   \n",
       "2                  17.585777              11.029480                26.113208   \n",
       "3                   0.000000               8.167067                22.695954   \n",
       "4                  15.920004               8.983022                23.756602   \n",
       "...                      ...                    ...                      ...   \n",
       "1542                0.000000               4.414812                19.830099   \n",
       "1543                0.000000               5.051807                19.857989   \n",
       "1544                0.000000               7.810829                22.459114   \n",
       "1545                0.000000               4.530445                19.456579   \n",
       "1546                0.000000               5.401562                20.136833   \n",
       "\n",
       "      x0_Campus  x0_NonResidential  x0_Nonresidential COS  \\\n",
       "0           0.0                1.0                    0.0   \n",
       "1           0.0                1.0                    0.0   \n",
       "2           0.0                1.0                    0.0   \n",
       "3           0.0                1.0                    0.0   \n",
       "4           0.0                1.0                    0.0   \n",
       "...         ...                ...                    ...   \n",
       "1542        0.0                0.0                    1.0   \n",
       "1543        0.0                0.0                    1.0   \n",
       "1544        0.0                0.0                    1.0   \n",
       "1545        0.0                0.0                    1.0   \n",
       "1546        0.0                0.0                    1.0   \n",
       "\n",
       "      x0_Nonresidential WA  ...  x3_1920's  x3_1930's  x3_1940's  x3_1950's  \\\n",
       "0                      0.0  ...        1.0        0.0        0.0        0.0   \n",
       "1                      0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2                      0.0  ...        0.0        0.0        0.0        0.0   \n",
       "3                      0.0  ...        1.0        0.0        0.0        0.0   \n",
       "4                      0.0  ...        0.0        0.0        0.0        0.0   \n",
       "...                    ...  ...        ...        ...        ...        ...   \n",
       "1542                   0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1543                   0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1544                   0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1545                   0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1546                   0.0  ...        0.0        1.0        0.0        0.0   \n",
       "\n",
       "      x3_1960's  x3_1970's  x3_1980's  x3_1990's  x3_2000's  x3_2010's  \n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1           0.0        0.0        0.0        1.0        0.0        0.0  \n",
       "2           1.0        0.0        0.0        0.0        0.0        0.0  \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "4           0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "1542        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1543        0.0        0.0        0.0        0.0        1.0        0.0  \n",
       "1544        0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "1545        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1546        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[1547 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lecture et affichage du fichier '2016_Building_Energy_Benchmarking_clean_model_1.csv'\n",
    "data=pd.read_csv('2016_Building_Energy_Benchmarking_clean_model_1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a641d887",
   "metadata": {},
   "source": [
    "### 1.1.2 Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865f2b9c",
   "metadata": {},
   "source": [
    "#### Séparation features / tagets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c331f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target y : SiteEnergyUse(kBtu)==> CONSOMMATION D'ENERGIE\n",
    "y=data['log_SiteEnergyUse(kBtu)'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efb90c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>x0_SPS-District K-12</th>\n",
       "      <th>x1_Distribution Center</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_1920's</th>\n",
       "      <th>x3_1930's</th>\n",
       "      <th>x3_1940's</th>\n",
       "      <th>x3_1950's</th>\n",
       "      <th>x3_1960's</th>\n",
       "      <th>x3_1970's</th>\n",
       "      <th>x3_1980's</th>\n",
       "      <th>x3_1990's</th>\n",
       "      <th>x3_2000's</th>\n",
       "      <th>x3_2010's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  x0_Campus  x0_NonResidential  \\\n",
       "0                   0.000000        0.0                1.0   \n",
       "1                  13.878913        0.0                1.0   \n",
       "2                  17.585777        0.0                1.0   \n",
       "3                   0.000000        0.0                1.0   \n",
       "4                  15.920004        0.0                1.0   \n",
       "...                      ...        ...                ...   \n",
       "1542                0.000000        0.0                0.0   \n",
       "1543                0.000000        0.0                0.0   \n",
       "1544                0.000000        0.0                0.0   \n",
       "1545                0.000000        0.0                0.0   \n",
       "1546                0.000000        0.0                0.0   \n",
       "\n",
       "      x0_Nonresidential COS  x0_Nonresidential WA  x0_SPS-District K-12  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "1542                    1.0                   0.0                   0.0   \n",
       "1543                    1.0                   0.0                   0.0   \n",
       "1544                    1.0                   0.0                   0.0   \n",
       "1545                    1.0                   0.0                   0.0   \n",
       "1546                    1.0                   0.0                   0.0   \n",
       "\n",
       "      x1_Distribution Center  ...  x3_1920's  x3_1930's  x3_1940's  x3_1950's  \\\n",
       "0                        0.0  ...        1.0        0.0        0.0        0.0   \n",
       "1                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "3                        0.0  ...        1.0        0.0        0.0        0.0   \n",
       "4                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "...                      ...  ...        ...        ...        ...        ...   \n",
       "1542                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1543                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1544                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1545                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1546                     0.0  ...        0.0        1.0        0.0        0.0   \n",
       "\n",
       "      x3_1960's  x3_1970's  x3_1980's  x3_1990's  x3_2000's  x3_2010's  \n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1           0.0        0.0        0.0        1.0        0.0        0.0  \n",
       "2           1.0        0.0        0.0        0.0        0.0        0.0  \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "4           0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "1542        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1543        0.0        0.0        0.0        0.0        1.0        0.0  \n",
       "1544        0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "1545        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1546        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[1547 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe des features, on retire les colonnes correspondant aux 2 targets\n",
    "model_1_data=data.copy()\n",
    "targets=['log_SiteEnergyUse(kBtu)','log_TotalGHGEmissions']\n",
    "model_1_data.drop(targets,axis=1, inplace=True)\n",
    "model_1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83924026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1547 entries, 0 to 1546\n",
      "Data columns (total 55 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   log_NumberofBuildings           1547 non-null   float64\n",
      " 1   log_NumberofFloors              1547 non-null   float64\n",
      " 2   log_PropertyGFATotal            1547 non-null   float64\n",
      " 3   log_PropertyGFAParking          1547 non-null   float64\n",
      " 4   x0_Campus                       1547 non-null   float64\n",
      " 5   x0_NonResidential               1547 non-null   float64\n",
      " 6   x0_Nonresidential COS           1547 non-null   float64\n",
      " 7   x0_Nonresidential WA            1547 non-null   float64\n",
      " 8   x0_SPS-District K-12            1547 non-null   float64\n",
      " 9   x1_Distribution Center          1547 non-null   float64\n",
      " 10  x1_Hospital                     1547 non-null   float64\n",
      " 11  x1_Hotel                        1547 non-null   float64\n",
      " 12  x1_K-12 School                  1547 non-null   float64\n",
      " 13  x1_Laboratory                   1547 non-null   float64\n",
      " 14  x1_Large Office                 1547 non-null   float64\n",
      " 15  x1_Low-Rise Multifamily         1547 non-null   float64\n",
      " 16  x1_Medical Office               1547 non-null   float64\n",
      " 17  x1_Mixed Use Property           1547 non-null   float64\n",
      " 18  x1_Other                        1547 non-null   float64\n",
      " 19  x1_Refrigerated Warehouse       1547 non-null   float64\n",
      " 20  x1_Residence Hall               1547 non-null   float64\n",
      " 21  x1_Restaurant                   1547 non-null   float64\n",
      " 22  x1_Retail Store                 1547 non-null   float64\n",
      " 23  x1_Self-Storage Facility        1547 non-null   float64\n",
      " 24  x1_Senior Care Community        1547 non-null   float64\n",
      " 25  x1_Small- and Mid-Sized Office  1547 non-null   float64\n",
      " 26  x1_Supermarket / Grocery Store  1547 non-null   float64\n",
      " 27  x1_University                   1547 non-null   float64\n",
      " 28  x1_Warehouse                    1547 non-null   float64\n",
      " 29  x1_Worship Facility             1547 non-null   float64\n",
      " 30  x2_BALLARD                      1547 non-null   float64\n",
      " 31  x2_CENTRAL                      1547 non-null   float64\n",
      " 32  x2_DELRIDGE                     1547 non-null   float64\n",
      " 33  x2_DOWNTOWN                     1547 non-null   float64\n",
      " 34  x2_EAST                         1547 non-null   float64\n",
      " 35  x2_GREATER DUWAMISH             1547 non-null   float64\n",
      " 36  x2_LAKE UNION                   1547 non-null   float64\n",
      " 37  x2_MAGNOLIA / QUEEN ANNE        1547 non-null   float64\n",
      " 38  x2_NORTH                        1547 non-null   float64\n",
      " 39  x2_NORTHEAST                    1547 non-null   float64\n",
      " 40  x2_NORTHWEST                    1547 non-null   float64\n",
      " 41  x2_SOUTHEAST                    1547 non-null   float64\n",
      " 42  x2_SOUTHWEST                    1547 non-null   float64\n",
      " 43  x3_1900's                       1547 non-null   float64\n",
      " 44  x3_1910's                       1547 non-null   float64\n",
      " 45  x3_1920's                       1547 non-null   float64\n",
      " 46  x3_1930's                       1547 non-null   float64\n",
      " 47  x3_1940's                       1547 non-null   float64\n",
      " 48  x3_1950's                       1547 non-null   float64\n",
      " 49  x3_1960's                       1547 non-null   float64\n",
      " 50  x3_1970's                       1547 non-null   float64\n",
      " 51  x3_1980's                       1547 non-null   float64\n",
      " 52  x3_1990's                       1547 non-null   float64\n",
      " 53  x3_2000's                       1547 non-null   float64\n",
      " 54  x3_2010's                       1547 non-null   float64\n",
      "dtypes: float64(55)\n",
      "memory usage: 664.9 KB\n"
     ]
    }
   ],
   "source": [
    "model_1_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b807f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 55)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Récupération des valeurs des features\n",
    "X=model_1_data.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e075fe",
   "metadata": {},
   "source": [
    "#### Standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4f181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04246324,  1.80319003,  0.35194475, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324,  1.68388254,  0.51427078, ...,  3.0405646 ,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324,  3.55118577,  2.79849165, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       ...,\n",
       "       [-0.04246324, -0.9868208 , -1.60606654, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324, -0.9868208 , -1.53486067, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324, -0.9868208 , -1.26936336, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardisation des données avec StandardScaler()\n",
    "std_scale = preprocessing.StandardScaler()\n",
    "X= std_scale.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d3a6f",
   "metadata": {},
   "source": [
    "#### Split du jeu de données en données d'entraînement et données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40e2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement X_train : (1237, 55)\n",
      "Taille du jeu de test X_test: (310, 55)\n",
      "Taille de y_train : (1237,)\n",
      "Taille de y_test : (310,)\n"
     ]
    }
   ],
   "source": [
    "# Split du jeu de données en données d'entraînement et données de test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42) # 20% des données dans le jeu de test\n",
    "print(\"Taille du jeu d'entraînement X_train : \"+ str(X_train.shape))\n",
    "print(\"Taille du jeu de test X_test: \"+ str(X_test.shape))\n",
    "print(\"Taille de y_train : \"+ str(y_train.shape))\n",
    "print(\"Taille de y_test : \"+ str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e9b280",
   "metadata": {},
   "source": [
    "# 1.2  Approche Naïve : DummyRegressor\n",
    "Regressor that makes predictions using simple rules.This regressor is useful as a simple baseline to compare with other (real) regressors.\n",
    "Strategy to use to generate predictions : {“mean”, “median”, “quantile”, “constant”}, default=”mean”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe3a85f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.57985758757657"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d499af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.92\n",
      "R2 : -0.00\n"
     ]
    }
   ],
   "source": [
    "#Strategie : Moyenne\n",
    "dum_reg = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entraînement\n",
    "dum_reg.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_dum = dum_reg.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_pred_dum)) ))\n",
    "print(\"R2 : {:.2f}\".format(dum_reg.score(X_test,y_test) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf11f68",
   "metadata": {},
   "source": [
    "Comme attendu, on trouve R2=0. R2 compare la performence du modèle par rapport une prédiction par la moyenne, hors notre modèle est une prédiction par la moyenne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0697579",
   "metadata": {},
   "source": [
    "## 1.3. Modèle linéaire : ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468f090",
   "metadata": {},
   "source": [
    "ElasticNet is a linear regression model trained with both l1 and l2 norm regularization of the coefficients. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of  and  using the l1_ratio parameter.\n",
    "\n",
    "Elastic-net is useful when there are multiple features that are correlated with one another. Lasso is likely to pick one of these at random, while elastic-net is likely to pick both.\n",
    "\n",
    "A practical advantage of trading-off between Lasso and Ridge is that it allows Elastic-Net to inherit some of Ridge’s stability under rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ac8648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.126e+02, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e+02, tolerance: 3.515e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.130e+02, tolerance: 3.475e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.041e+02, tolerance: 3.524e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.064e+02, tolerance: 3.500e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+02, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+02, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+02, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e+02, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+02, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.728e+01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.998e+01, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.706e+01, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.349e+01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.494e+01, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.316e+01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+01, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.997e+01, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.498e+01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.795e+01, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.900e+01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e+01, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.083e+00, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.141e+01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.549e+01, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.752e+01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+01, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.136e+00, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.675e+01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.440e+01, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.686e+01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.897e+00, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.217e+00, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.634e+01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.397e+01, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.666e+01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.764e+00, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+00, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+00, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.393e+01, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.676e+01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+00, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.131e-01, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+00, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.413e+01, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.893e-01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.649e+00, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.726e-01, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e+00, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+01, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.137e+02, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+02, tolerance: 3.515e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.142e+02, tolerance: 3.475e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.052e+02, tolerance: 3.524e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.075e+02, tolerance: 3.500e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+00, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.660e-01, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.899e-01, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+00, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.711e+00, tolerance: 3.500e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.459e-01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.631e-01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.539e-01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.626e-01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.075e-01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.107e-01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.906e-01, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.773e-01, tolerance: 3.475e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.839e-01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.957e-01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e-01, tolerance: 3.515e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.917e-01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.129e-01, tolerance: 3.536e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.388e-01, tolerance: 3.524e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.248e+02, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.074e+02, tolerance: 3.515e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.252e+02, tolerance: 3.475e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.163e+02, tolerance: 3.524e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.183e+02, tolerance: 3.500e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.165e+02, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.948e+02, tolerance: 3.515e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.167e+02, tolerance: 3.475e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.082e+02, tolerance: 3.524e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+02, tolerance: 3.500e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.178e+02, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.884e+02, tolerance: 3.515e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.164e+02, tolerance: 3.475e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.121e+02, tolerance: 3.524e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.052e+02, tolerance: 3.500e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+03, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+03, tolerance: 3.515e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+03, tolerance: 3.475e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+03, tolerance: 3.524e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+03, tolerance: 3.500e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e+03, tolerance: 3.536e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+03, tolerance: 3.515e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+03, tolerance: 3.475e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e+03, tolerance: 3.524e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.720e+03, tolerance: 3.500e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats de la validation croisée :\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.0}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.1}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.2}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.4}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.5}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.8}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.0001, 'l1_ratio': 0.9}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.001, 'l1_ratio': 0.1}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.001, 'l1_ratio': 0.2}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.001, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.001, 'l1_ratio': 0.4}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.001, 'l1_ratio': 0.5}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.001, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.741 (+/-0.034) for {'alpha': 0.001, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.741 (+/-0.034) for {'alpha': 0.001, 'l1_ratio': 0.8}\n",
      "r2 = 0.741 (+/-0.034) for {'alpha': 0.001, 'l1_ratio': 0.9}\n",
      "r2 = 0.741 (+/-0.036) for {'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.01, 'l1_ratio': 0.1}\n",
      "r2 = 0.741 (+/-0.035) for {'alpha': 0.01, 'l1_ratio': 0.2}\n",
      "r2 = 0.742 (+/-0.034) for {'alpha': 0.01, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.742 (+/-0.034) for {'alpha': 0.01, 'l1_ratio': 0.4}\n",
      "r2 = 0.742 (+/-0.033) for {'alpha': 0.01, 'l1_ratio': 0.5}\n",
      "r2 = 0.742 (+/-0.033) for {'alpha': 0.01, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.742 (+/-0.033) for {'alpha': 0.01, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.742 (+/-0.032) for {'alpha': 0.01, 'l1_ratio': 0.8}\n",
      "r2 = 0.742 (+/-0.032) for {'alpha': 0.01, 'l1_ratio': 0.9}\n",
      "r2 = 0.733 (+/-0.043) for {'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "r2 = 0.734 (+/-0.041) for {'alpha': 0.1, 'l1_ratio': 0.1}\n",
      "r2 = 0.733 (+/-0.039) for {'alpha': 0.1, 'l1_ratio': 0.2}\n",
      "r2 = 0.732 (+/-0.039) for {'alpha': 0.1, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.729 (+/-0.037) for {'alpha': 0.1, 'l1_ratio': 0.4}\n",
      "r2 = 0.726 (+/-0.036) for {'alpha': 0.1, 'l1_ratio': 0.5}\n",
      "r2 = 0.722 (+/-0.034) for {'alpha': 0.1, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.719 (+/-0.033) for {'alpha': 0.1, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.715 (+/-0.032) for {'alpha': 0.1, 'l1_ratio': 0.8}\n",
      "r2 = 0.710 (+/-0.031) for {'alpha': 0.1, 'l1_ratio': 0.9}\n",
      "r2 = 0.609 (+/-0.052) for {'alpha': 1, 'l1_ratio': 0.0}\n",
      "r2 = 0.563 (+/-0.040) for {'alpha': 1, 'l1_ratio': 0.1}\n",
      "r2 = 0.508 (+/-0.036) for {'alpha': 1, 'l1_ratio': 0.2}\n",
      "r2 = 0.464 (+/-0.037) for {'alpha': 1, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.439 (+/-0.035) for {'alpha': 1, 'l1_ratio': 0.4}\n",
      "r2 = 0.421 (+/-0.030) for {'alpha': 1, 'l1_ratio': 0.5}\n",
      "r2 = 0.406 (+/-0.028) for {'alpha': 1, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.392 (+/-0.027) for {'alpha': 1, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.375 (+/-0.024) for {'alpha': 1, 'l1_ratio': 0.8}\n",
      "r2 = 0.354 (+/-0.022) for {'alpha': 1, 'l1_ratio': 0.9}\n",
      "r2 = 0.231 (+/-0.020) for {'alpha': 10, 'l1_ratio': 0.0}\n",
      "r2 = 0.035 (+/-0.008) for {'alpha': 10, 'l1_ratio': 0.1}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 10, 'l1_ratio': 0.2}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 10, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 10, 'l1_ratio': 0.4}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 10, 'l1_ratio': 0.5}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 10, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 10, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 10, 'l1_ratio': 0.8}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 10, 'l1_ratio': 0.9}\n",
      "r2 = 0.029 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.0}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.1}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.2}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.4}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.5}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.8}\n",
      "r2 = -0.004 (+/-0.007) for {'alpha': 100, 'l1_ratio': 0.9}\n"
     ]
    }
   ],
   "source": [
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef de régularisation. Si égale à 0, équivaut à régresison linéaire simple\n",
    "              \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}#L1 ratio , si égal à 1 équivaut à un Lasso, si égal 0 à un Ridge\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "elastic_net_grid = model_selection.GridSearchCV(estimator = linear_model.ElasticNet(),  # ElasticNet regression\n",
    "                      param_grid = parameters,  # hyperparamètres à tester\n",
    "                    scoring = score,  # score à optimiser R2\n",
    "\n",
    "                      #scoring = 'neg_root_mean_squared_error',  # score à optimiserRMSE\n",
    "                      cv=5, # nombre de folds de validation croisée\n",
    "                      verbose=0\n",
    "                     )\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "elastic_net_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(\n",
    "        elastic_net_grid.cv_results_['mean_test_score'], # score moyen\n",
    "        elastic_net_grid.cv_results_['std_test_score'],  # écart-type du score\n",
    "        elastic_net_grid.cv_results_['params']           # valeur de l'hyperparamètre\n",
    "):\n",
    "\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(score,\n",
    "                                                   mean,\n",
    "                                                   std*2,\n",
    "                                                   params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd1c3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03619814, 0.03599954, 0.03579922, 0.03579936, 0.03539882,\n",
       "        0.03499842, 0.0355988 , 0.03519788, 0.03519964, 0.03379908,\n",
       "        0.03619947, 0.0335988 , 0.03099842, 0.02719755, 0.02579842,\n",
       "        0.02579746, 0.02799969, 0.02939911, 0.02759886, 0.02639828,\n",
       "        0.03539982, 0.00400014, 0.00359988, 0.00339904, 0.00379977,\n",
       "        0.00379896, 0.00459967, 0.00379939, 0.00279975, 0.00219922,\n",
       "        0.03559794, 0.00120058, 0.00099998, 0.00079994, 0.00080013,\n",
       "        0.00079994, 0.00059996, 0.00099993, 0.00040007, 0.        ,\n",
       "        0.0357985 , 0.0010005 , 0.00100002, 0.00040002, 0.00040007,\n",
       "        0.00099998, 0.        , 0.00099993, 0.00020003, 0.00059996,\n",
       "        0.03559785, 0.        , 0.00059996, 0.00039997, 0.00019994,\n",
       "        0.00080004, 0.0006    , 0.00020008, 0.00059996, 0.00059996,\n",
       "        0.03579793, 0.0006    , 0.0006    , 0.00020003, 0.00059991,\n",
       "        0.00059991, 0.00019999, 0.00040002, 0.00059996, 0.00040002]),\n",
       " 'std_fit_time': array([3.65487901e-03, 2.89778577e-03, 2.71329098e-03, 2.63806606e-03,\n",
       "        2.57647462e-03, 2.44911761e-03, 2.41518307e-03, 2.71280920e-03,\n",
       "        3.18792968e-03, 3.24932712e-03, 2.78523962e-03, 2.80024686e-03,\n",
       "        4.56058038e-03, 7.73023211e-03, 8.72673177e-03, 9.51638472e-03,\n",
       "        1.09178483e-02, 1.18768061e-02, 1.19935923e-02, 1.19432812e-02,\n",
       "        2.93966141e-03, 8.94522329e-04, 4.89590192e-04, 8.00717084e-04,\n",
       "        1.16607335e-03, 1.46938636e-03, 2.24319631e-03, 1.16502717e-03,\n",
       "        1.16393099e-03, 7.47997329e-04, 3.20032551e-03, 4.01067861e-04,\n",
       "        2.78041453e-07, 3.99971008e-04, 4.00066461e-04, 3.99971150e-04,\n",
       "        4.89862464e-04, 3.01578299e-07, 4.89979242e-04, 0.00000000e+00,\n",
       "        2.63742265e-03, 1.16410786e-06, 1.16800773e-07, 4.89920847e-04,\n",
       "        4.89979265e-04, 9.53674316e-08, 0.00000000e+00, 1.50789149e-07,\n",
       "        4.00066376e-04, 4.89862464e-04, 3.20059682e-03, 0.00000000e+00,\n",
       "        4.89862464e-04, 4.89862441e-04, 3.99875641e-04, 4.00018706e-04,\n",
       "        4.89901382e-04, 4.00161743e-04, 4.89862441e-04, 4.89862464e-04,\n",
       "        3.05875684e-03, 4.89902357e-04, 4.89901429e-04, 4.00066376e-04,\n",
       "        4.89823515e-04, 4.89823562e-04, 3.99971008e-04, 4.89920847e-04,\n",
       "        4.89862441e-04, 4.89920847e-04]),\n",
       " 'mean_score_time': array([0.00040064, 0.00020018, 0.00020032, 0.        , 0.00040078,\n",
       "        0.00100179, 0.00040083, 0.0006012 , 0.00020046, 0.00020027,\n",
       "        0.00020041, 0.0004005 , 0.0004005 , 0.00040121, 0.        ,\n",
       "        0.00020046, 0.00020037, 0.00020037, 0.00040064, 0.        ,\n",
       "        0.00020037, 0.00039983, 0.00060034, 0.00020022, 0.00020032,\n",
       "        0.00020027, 0.00040026, 0.        , 0.00039978, 0.00020008,\n",
       "        0.00040088, 0.00020008, 0.        , 0.00040002, 0.00019999,\n",
       "        0.00019999, 0.00040007, 0.        , 0.        , 0.        ,\n",
       "        0.00020041, 0.        , 0.        , 0.00059996, 0.        ,\n",
       "        0.        , 0.00040002, 0.        , 0.00019994, 0.00019999,\n",
       "        0.00060158, 0.00040011, 0.00040002, 0.        , 0.00040011,\n",
       "        0.00019999, 0.        , 0.00019989, 0.00040007, 0.        ,\n",
       "        0.        , 0.00040002, 0.        , 0.00020003, 0.00040002,\n",
       "        0.        , 0.00040002, 0.00040007, 0.00020003, 0.00019999]),\n",
       " 'std_score_time': array([4.90680070e-04, 4.00352478e-04, 4.00638580e-04, 0.00000000e+00,\n",
       "        4.90855300e-04, 7.74768677e-07, 4.90913648e-04, 4.90874769e-04,\n",
       "        4.00924683e-04, 4.00543213e-04, 4.00829315e-04, 4.90504851e-04,\n",
       "        4.90504851e-04, 4.91381221e-04, 0.00000000e+00, 4.00924683e-04,\n",
       "        4.00733948e-04, 4.00733948e-04, 4.90680255e-04, 0.00000000e+00,\n",
       "        4.00733948e-04, 4.89687292e-04, 4.90174150e-04, 4.00447845e-04,\n",
       "        4.00638580e-04, 4.00543213e-04, 4.90213215e-04, 0.00000000e+00,\n",
       "        4.89628840e-04, 4.00161743e-04, 4.90972101e-04, 4.00161743e-04,\n",
       "        0.00000000e+00, 4.89920847e-04, 3.99971008e-04, 3.99971008e-04,\n",
       "        4.89979242e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.00829315e-04, 0.00000000e+00, 0.00000000e+00, 4.89862441e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.89920847e-04, 0.00000000e+00,\n",
       "        3.99875641e-04, 3.99971008e-04, 4.91186469e-04, 4.90037787e-04,\n",
       "        4.89920847e-04, 0.00000000e+00, 4.90037648e-04, 3.99971008e-04,\n",
       "        0.00000000e+00, 3.99780273e-04, 4.89979265e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.89920847e-04, 0.00000000e+00, 4.00066376e-04,\n",
       "        4.89920847e-04, 0.00000000e+00, 4.89920847e-04, 4.89981562e-04,\n",
       "        4.00066376e-04, 3.99971008e-04]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_l1_ratio': masked_array(data=[0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001, 'l1_ratio': 0.0},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9}],\n",
       " 'split0_test_score': array([ 7.50900603e-01,  7.50903586e-01,  7.50905651e-01,  7.50909416e-01,\n",
       "         7.50913244e-01,  7.50916290e-01,  7.50919326e-01,  7.50922350e-01,\n",
       "         7.50925363e-01,  7.50920158e-01,  7.51002505e-01,  7.51034326e-01,\n",
       "         7.51054147e-01,  7.51073549e-01,  7.51092466e-01,  7.51110892e-01,\n",
       "         7.51128829e-01,  7.51146279e-01,  7.51163238e-01,  7.51179707e-01,\n",
       "         7.51812633e-01,  7.52089815e-01,  7.52225884e-01,  7.52317578e-01,\n",
       "         7.52279917e-01,  7.52228499e-01,  7.52139517e-01,  7.52059623e-01,\n",
       "         7.51931137e-01,  7.51847010e-01,  7.47758070e-01,  7.47354176e-01,\n",
       "         7.44939172e-01,  7.40854829e-01,  7.35141997e-01,  7.30101910e-01,\n",
       "         7.25476443e-01,  7.21170258e-01,  7.17808947e-01,  7.13870467e-01,\n",
       "         6.25497341e-01,  5.71003052e-01,  5.12209022e-01,  4.67976305e-01,\n",
       "         4.44645986e-01,  4.27016001e-01,  4.11339333e-01,  3.97692091e-01,\n",
       "         3.81234257e-01,  3.61045671e-01,  2.42258750e-01,  4.00551023e-02,\n",
       "        -2.17295789e-04, -2.17295789e-04, -2.17295789e-04, -2.17295789e-04,\n",
       "        -2.17295789e-04, -2.17295789e-04, -2.17295789e-04, -2.17295789e-04,\n",
       "         3.35869358e-02, -2.17295789e-04, -2.17295789e-04, -2.17295789e-04,\n",
       "        -2.17295789e-04, -2.17295789e-04, -2.17295789e-04, -2.17295789e-04,\n",
       "        -2.17295789e-04, -2.17295789e-04]),\n",
       " 'split1_test_score': array([ 0.71351143,  0.71354873,  0.71358368,  0.71361726,  0.71362922,\n",
       "         0.71364083,  0.71365246,  0.71365853,  0.71366437,  0.71367022,\n",
       "         0.71351201,  0.71357576,  0.71362614,  0.71367001,  0.71370856,\n",
       "         0.71374677,  0.71378463,  0.71382218,  0.71385944,  0.71389657,\n",
       "         0.7124497 ,  0.71283867,  0.71320123,  0.71349734,  0.71375014,\n",
       "         0.71397119,  0.71415096,  0.71429947,  0.71448616,  0.71465052,\n",
       "         0.69659345,  0.69742324,  0.69698883,  0.69490743,  0.69375955,\n",
       "         0.69179985,  0.68898956,  0.68675577,  0.68338696,  0.67937657,\n",
       "         0.56246527,  0.52716959,  0.47630982,  0.43352718,  0.4114979 ,\n",
       "         0.399602  ,  0.38588779,  0.37375104,  0.35909396,  0.3410869 ,\n",
       "         0.21481897,  0.03666323, -0.00222415, -0.00222415, -0.00222415,\n",
       "        -0.00222415, -0.00222415, -0.00222415, -0.00222415, -0.00222415,\n",
       "         0.02814445, -0.00222415, -0.00222415, -0.00222415, -0.00222415,\n",
       "        -0.00222415, -0.00222415, -0.00222415, -0.00222415, -0.00222415]),\n",
       " 'split2_test_score': array([ 0.76544355,  0.76544098,  0.76543767,  0.76543435,  0.76543098,\n",
       "         0.76542758,  0.76542416,  0.76541979,  0.76541394,  0.76540996,\n",
       "         0.76550218,  0.76547556,  0.76543601,  0.76539663,  0.7653577 ,\n",
       "         0.76531839,  0.7652787 ,  0.76523866,  0.76519811,  0.76515701,\n",
       "         0.76592325,  0.76562385,  0.76520666,  0.76475011,  0.76427249,\n",
       "         0.76375932,  0.76323999,  0.7627944 ,  0.76235732,  0.76192254,\n",
       "         0.76050424,  0.75742532,  0.7548883 ,  0.7514996 ,  0.74723902,\n",
       "         0.74267944,  0.73704868,  0.73088944,  0.72370016,  0.71556731,\n",
       "         0.63982076,  0.58709331,  0.53170399,  0.48908029,  0.45923756,\n",
       "         0.43451757,  0.41880825,  0.40329586,  0.38439236,  0.36092175,\n",
       "         0.24054427,  0.03198082, -0.00674845, -0.00674845, -0.00674845,\n",
       "        -0.00674845, -0.00674845, -0.00674845, -0.00674845, -0.00674845,\n",
       "         0.02739303, -0.00674845, -0.00674845, -0.00674845, -0.00674845,\n",
       "        -0.00674845, -0.00674845, -0.00674845, -0.00674845, -0.00674845]),\n",
       " 'split3_test_score': array([ 0.73279701,  0.73280534,  0.73281468,  0.73282358,  0.73283026,\n",
       "         0.73283819,  0.7328465 ,  0.73284802,  0.7328554 ,  0.73286277,\n",
       "         0.73287721,  0.73294978,  0.73302063,  0.73309284,  0.73316133,\n",
       "         0.73323112,  0.73329902,  0.73336773,  0.73343614,  0.73350426,\n",
       "         0.73350475,  0.73418766,  0.73483785,  0.73544267,  0.73599007,\n",
       "         0.7364637 ,  0.73691085,  0.73732325,  0.73770006,  0.7380235 ,\n",
       "         0.7296744 ,  0.73177161,  0.73268832,  0.73195616,  0.73172195,\n",
       "         0.73016084,  0.72790903,  0.72546857,  0.72292901,  0.72139721,\n",
       "         0.61341342,  0.56964029,  0.51409053,  0.47387388,  0.45309631,\n",
       "         0.43660127,  0.42115436,  0.4061824 ,  0.38812175,  0.36595761,\n",
       "         0.23317104,  0.03800254, -0.00216786, -0.00216786, -0.00216786,\n",
       "        -0.00216786, -0.00216786, -0.00216786, -0.00216786, -0.00216786,\n",
       "         0.03047703, -0.00216786, -0.00216786, -0.00216786, -0.00216786,\n",
       "        -0.00216786, -0.00216786, -0.00216786, -0.00216786, -0.00216786]),\n",
       " 'split4_test_score': array([ 0.74006392,  0.74006856,  0.74007418,  0.74008336,  0.74008961,\n",
       "         0.74009576,  0.74010179,  0.74010623,  0.74011181,  0.74010963,\n",
       "         0.74022917,  0.74032894,  0.74039737,  0.74042448,  0.74047204,\n",
       "         0.74053265,  0.74059954,  0.74066802,  0.74073889,  0.74081017,\n",
       "         0.74013103,  0.74109317,  0.74194594,  0.74257012,  0.74317032,\n",
       "         0.74377336,  0.74433822,  0.74492009,  0.7455255 ,  0.74603806,\n",
       "         0.73090868,  0.73461758,  0.73650629,  0.73848177,  0.73791201,\n",
       "         0.73581782,  0.73244301,  0.7287144 ,  0.72498949,  0.72109991,\n",
       "         0.60582582,  0.56106895,  0.50357742,  0.45764509,  0.42619997,\n",
       "         0.40801278,  0.39227689,  0.3782173 ,  0.36135605,  0.34080171,\n",
       "         0.22655071,  0.02944576, -0.00941193, -0.00941193, -0.00941193,\n",
       "        -0.00941193, -0.00941193, -0.00941193, -0.00941193, -0.00941193,\n",
       "         0.02332853, -0.00941193, -0.00941193, -0.00941193, -0.00941193,\n",
       "        -0.00941193, -0.00941193, -0.00941193, -0.00941193, -0.00941193]),\n",
       " 'mean_test_score': array([ 0.7405433 ,  0.74055344,  0.74056317,  0.74057359,  0.74057866,\n",
       "         0.74058373,  0.74058885,  0.74059098,  0.74059418,  0.74059455,\n",
       "         0.74062461,  0.74067287,  0.74070686,  0.7407315 ,  0.74075842,\n",
       "         0.74078796,  0.74081814,  0.74084857,  0.74087917,  0.74090955,\n",
       "         0.74076427,  0.74116663,  0.74148351,  0.74171556,  0.74189259,\n",
       "         0.74203921,  0.74215591,  0.74227937,  0.74240004,  0.74249633,\n",
       "         0.73308777,  0.73371838,  0.73320218,  0.73153996,  0.72915491,\n",
       "         0.72611197,  0.72237335,  0.71859969,  0.71456291,  0.71026229,\n",
       "         0.60940452,  0.56319504,  0.50757816,  0.46442055,  0.43893554,\n",
       "         0.42114992,  0.40589332,  0.39182774,  0.37483967,  0.35396273,\n",
       "         0.23146875,  0.03522949, -0.00415394, -0.00415394, -0.00415394,\n",
       "        -0.00415394, -0.00415394, -0.00415394, -0.00415394, -0.00415394,\n",
       "         0.02858599, -0.00415394, -0.00415394, -0.00415394, -0.00415394,\n",
       "        -0.00415394, -0.00415394, -0.00415394, -0.00415394, -0.00415394]),\n",
       " 'std_test_score': array([0.01742557, 0.01741286, 0.01740045, 0.01738869, 0.01738385,\n",
       "        0.01737889, 0.0173739 , 0.01737097, 0.01736715, 0.01736293,\n",
       "        0.01744629, 0.0174158 , 0.01738469, 0.01735566, 0.01732865,\n",
       "        0.01730146, 0.0172744 , 0.01724726, 0.01722009, 0.01719281,\n",
       "        0.01794356, 0.01771246, 0.01744966, 0.01720082, 0.01695421,\n",
       "        0.01671821, 0.01649704, 0.01631521, 0.01612562, 0.01595464,\n",
       "        0.02151797, 0.02034645, 0.0196501 , 0.01936728, 0.0184336 ,\n",
       "        0.01776693, 0.01715525, 0.01625528, 0.01577765, 0.01572597,\n",
       "        0.02613923, 0.01987957, 0.01810871, 0.01849551, 0.01766537,\n",
       "        0.01475633, 0.01424768, 0.01329643, 0.01215149, 0.01078399,\n",
       "        0.01003084, 0.00392524, 0.00339245, 0.00339245, 0.00339245,\n",
       "        0.00339245, 0.00339245, 0.00339245, 0.00339245, 0.00339245,\n",
       "        0.00340131, 0.00339245, 0.00339245, 0.00339245, 0.00339245,\n",
       "        0.00339245, 0.00339245, 0.00339245, 0.00339245, 0.00339245]),\n",
       " 'rank_test_score': array([30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 14, 13,\n",
       "        12, 11, 10, 15,  9,  8,  7,  6,  5,  4,  3,  2,  1, 33, 31, 32, 34,\n",
       "        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "        52, 54, 54, 54, 54, 54, 54, 54, 54, 53, 54, 54, 54, 54, 54, 54, 54,\n",
       "        54, 54])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Résultats complets du GridSearch\n",
    "elastic_net_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfefa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'l1_ratio': 0.9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage les hyperparamètres optimaux\n",
    "print(\"Les meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net :\")\n",
    "elastic_net_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b66f0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs paramètres\n",
    "y_el_net_pred=elastic_net_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28085779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.06\n",
      "R2 test : 0.70\n",
      "R2 train : 0.7424963253819621\n",
      "Temps d'execution :0.01250805105481829 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Elastic Net sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_el_net_pred)) ))\n",
    "print(\"R2 test : {:.2f}\".format(elastic_net_grid.score(X_test,y_test) ))\n",
    "print(\"R2 train : \" + str(elastic_net_grid.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (elastic_net_grid.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df861d1",
   "metadata": {},
   "source": [
    "# 1.4 Modèle non linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfdc0c8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89136233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.7s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.7s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.2s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.1s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.5s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.5s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'min_samples_leaf': [1, 3, 5, 10],\n",
       "                         'n_estimators': [10, 50, 100, 300, 500]},\n",
       "             scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\n",
    "    'n_estimators' : [10,50,100,300,500], #nombre d'arbres de décision\n",
    "    'min_samples_leaf' : [1,3,5,10], #nombre de feuilles minimales dans un noeud\n",
    "}\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "\n",
    "random_forest_grid = model_selection.GridSearchCV(RandomForestRegressor(),\n",
    "                               param_grid = parameters,\n",
    "                               scoring=score,\n",
    "                              verbose=2,\n",
    "                               cv=5)\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "random_forest_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb23787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs hyperparamètres pour le modèle non linéaire Random Forest \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 3, 'n_estimators': 500}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les hyperparamètres optimaux\n",
    "print(\"Les meilleurs hyperparamètres pour le modèle non linéaire Random Forest \")\n",
    "random_forest_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58030930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs parametres\n",
    "y_rand_for_pred = random_forest_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ca4c125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.11\n",
      "R2 test : 0.67\n",
      "R2 train : 0.7044477126452161\n",
      "Temps d'execution :0.46115902185440066 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Random Forest sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_rand_for_pred)) ))\n",
    "print(\"R2 test : {:.2f}\".format(random_forest_grid.score(X_test,y_test) ))\n",
    "print(\"R2 train : \"+ str(random_forest_grid.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (random_forest_grid.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a24c36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.9 ms ± 94.7 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit random_forest_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ffa3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1d3622",
   "metadata": {},
   "source": [
    "# <a name=\"C2\">2. Deuxième itération </a>\n",
    "## 2.1 Import et préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a382383",
   "metadata": {},
   "source": [
    "### 2.1 Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "130aac48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>log_TotalGHGEmissions</th>\n",
       "      <th>log_SiteEnergyUse(kBtu)</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Non-Refrigerated Warehouse</th>\n",
       "      <th>x0_Other - Recreation</th>\n",
       "      <th>x0_Supermarket/Grocery Store</th>\n",
       "      <th>x0_Worship Facility</th>\n",
       "      <th>x0_Restaurant</th>\n",
       "      <th>Office</th>\n",
       "      <th>Other</th>\n",
       "      <th>Retail Store</th>\n",
       "      <th>infrequent</th>\n",
       "      <th>Parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.971429</td>\n",
       "      <td>22.784838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>8.213639</td>\n",
       "      <td>22.999884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>11.029480</td>\n",
       "      <td>26.113208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.167067</td>\n",
       "      <td>22.695954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>8.983022</td>\n",
       "      <td>23.756602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.414812</td>\n",
       "      <td>19.830099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.051807</td>\n",
       "      <td>19.857989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.810829</td>\n",
       "      <td>22.459114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423653</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.530445</td>\n",
       "      <td>19.456579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.401562</td>\n",
       "      <td>20.136833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  log_TotalGHGEmissions  log_SiteEnergyUse(kBtu)  \\\n",
       "0                   0.000000               7.971429                22.784838   \n",
       "1                  13.878913               8.213639                22.999884   \n",
       "2                  17.585777              11.029480                26.113208   \n",
       "3                   0.000000               8.167067                22.695954   \n",
       "4                  15.920004               8.983022                23.756602   \n",
       "...                      ...                    ...                      ...   \n",
       "1542                0.000000               4.414812                19.830099   \n",
       "1543                0.000000               5.051807                19.857989   \n",
       "1544                0.000000               7.810829                22.459114   \n",
       "1545                0.000000               4.530445                19.456579   \n",
       "1546                0.000000               5.401562                20.136833   \n",
       "\n",
       "      x0_Campus  x0_NonResidential  x0_Nonresidential COS  \\\n",
       "0           0.0                1.0                    0.0   \n",
       "1           0.0                1.0                    0.0   \n",
       "2           0.0                1.0                    0.0   \n",
       "3           0.0                1.0                    0.0   \n",
       "4           0.0                1.0                    0.0   \n",
       "...         ...                ...                    ...   \n",
       "1542        0.0                0.0                    1.0   \n",
       "1543        0.0                0.0                    1.0   \n",
       "1544        0.0                0.0                    1.0   \n",
       "1545        0.0                0.0                    1.0   \n",
       "1546        0.0                0.0                    1.0   \n",
       "\n",
       "      x0_Nonresidential WA  ...  x0_Non-Refrigerated Warehouse  \\\n",
       "0                      0.0  ...                            0.0   \n",
       "1                      0.0  ...                            0.0   \n",
       "2                      0.0  ...                            0.0   \n",
       "3                      0.0  ...                            0.0   \n",
       "4                      0.0  ...                            0.0   \n",
       "...                    ...  ...                            ...   \n",
       "1542                   0.0  ...                            0.0   \n",
       "1543                   0.0  ...                            0.0   \n",
       "1544                   0.0  ...                            0.0   \n",
       "1545                   0.0  ...                            0.0   \n",
       "1546                   0.0  ...                            0.0   \n",
       "\n",
       "      x0_Other - Recreation  x0_Supermarket/Grocery Store  \\\n",
       "0                  0.000000                           0.0   \n",
       "1                  0.000000                           0.0   \n",
       "2                  0.000000                           0.0   \n",
       "3                  0.000000                           0.0   \n",
       "4                  0.000000                           0.0   \n",
       "...                     ...                           ...   \n",
       "1542               1.000000                           0.0   \n",
       "1543               1.000000                           0.0   \n",
       "1544               0.576347                           0.0   \n",
       "1545               0.485868                           0.0   \n",
       "1546               0.475919                           0.0   \n",
       "\n",
       "      x0_Worship Facility  x0_Restaurant  Office  Other  Retail Store  \\\n",
       "0                     0.0       0.000000     0.0    0.0           0.0   \n",
       "1                     0.0       0.044629     0.0    0.0           0.0   \n",
       "2                     0.0       0.000000     0.0    0.0           0.0   \n",
       "3                     0.0       0.000000     0.0    0.0           0.0   \n",
       "4                     0.0       0.000000     0.0    0.0           0.0   \n",
       "...                   ...            ...     ...    ...           ...   \n",
       "1542                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1543                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1544                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1545                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1546                  0.0       0.000000     0.0    0.0           0.0   \n",
       "\n",
       "      infrequent   Parking  \n",
       "0       0.000000  0.000000  \n",
       "1       0.000000  0.145453  \n",
       "2       0.000000  0.000000  \n",
       "3       0.000000  0.000000  \n",
       "4       0.000000  0.355224  \n",
       "...          ...       ...  \n",
       "1542    0.000000  0.000000  \n",
       "1543    0.000000  0.000000  \n",
       "1544    0.423653  0.000000  \n",
       "1545    0.514132  0.000000  \n",
       "1546    0.524081  0.000000  \n",
       "\n",
       "[1547 rows x 71 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lecture et affichage du fichier '2016_Building_Energy_Benchmarking_clean_model_2.csv'\n",
    "data_2=pd.read_csv('2016_Building_Energy_Benchmarking_clean_model_2.csv')\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b29a7c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1547 entries, 0 to 1546\n",
      "Data columns (total 71 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   log_NumberofBuildings           1547 non-null   float64\n",
      " 1   log_NumberofFloors              1547 non-null   float64\n",
      " 2   log_PropertyGFATotal            1547 non-null   float64\n",
      " 3   log_PropertyGFAParking          1547 non-null   float64\n",
      " 4   log_TotalGHGEmissions           1547 non-null   float64\n",
      " 5   log_SiteEnergyUse(kBtu)         1547 non-null   float64\n",
      " 6   x0_Campus                       1547 non-null   float64\n",
      " 7   x0_NonResidential               1547 non-null   float64\n",
      " 8   x0_Nonresidential COS           1547 non-null   float64\n",
      " 9   x0_Nonresidential WA            1547 non-null   float64\n",
      " 10  x0_SPS-District K-12            1547 non-null   float64\n",
      " 11  x1_Distribution Center          1547 non-null   float64\n",
      " 12  x1_Hospital                     1547 non-null   float64\n",
      " 13  x1_Hotel                        1547 non-null   float64\n",
      " 14  x1_K-12 School                  1547 non-null   float64\n",
      " 15  x1_Laboratory                   1547 non-null   float64\n",
      " 16  x1_Large Office                 1547 non-null   float64\n",
      " 17  x1_Low-Rise Multifamily         1547 non-null   float64\n",
      " 18  x1_Medical Office               1547 non-null   float64\n",
      " 19  x1_Mixed Use Property           1547 non-null   float64\n",
      " 20  x1_Other                        1547 non-null   float64\n",
      " 21  x1_Refrigerated Warehouse       1547 non-null   float64\n",
      " 22  x1_Residence Hall               1547 non-null   float64\n",
      " 23  x1_Restaurant                   1547 non-null   float64\n",
      " 24  x1_Retail Store                 1547 non-null   float64\n",
      " 25  x1_Self-Storage Facility        1547 non-null   float64\n",
      " 26  x1_Senior Care Community        1547 non-null   float64\n",
      " 27  x1_Small- and Mid-Sized Office  1547 non-null   float64\n",
      " 28  x1_Supermarket / Grocery Store  1547 non-null   float64\n",
      " 29  x1_University                   1547 non-null   float64\n",
      " 30  x1_Warehouse                    1547 non-null   float64\n",
      " 31  x1_Worship Facility             1547 non-null   float64\n",
      " 32  x2_BALLARD                      1547 non-null   float64\n",
      " 33  x2_CENTRAL                      1547 non-null   float64\n",
      " 34  x2_DELRIDGE                     1547 non-null   float64\n",
      " 35  x2_DOWNTOWN                     1547 non-null   float64\n",
      " 36  x2_EAST                         1547 non-null   float64\n",
      " 37  x2_GREATER DUWAMISH             1547 non-null   float64\n",
      " 38  x2_LAKE UNION                   1547 non-null   float64\n",
      " 39  x2_MAGNOLIA / QUEEN ANNE        1547 non-null   float64\n",
      " 40  x2_NORTH                        1547 non-null   float64\n",
      " 41  x2_NORTHEAST                    1547 non-null   float64\n",
      " 42  x2_NORTHWEST                    1547 non-null   float64\n",
      " 43  x2_SOUTHEAST                    1547 non-null   float64\n",
      " 44  x2_SOUTHWEST                    1547 non-null   float64\n",
      " 45  x3_1900's                       1547 non-null   float64\n",
      " 46  x3_1910's                       1547 non-null   float64\n",
      " 47  x3_1920's                       1547 non-null   float64\n",
      " 48  x3_1930's                       1547 non-null   float64\n",
      " 49  x3_1940's                       1547 non-null   float64\n",
      " 50  x3_1950's                       1547 non-null   float64\n",
      " 51  x3_1960's                       1547 non-null   float64\n",
      " 52  x3_1970's                       1547 non-null   float64\n",
      " 53  x3_1980's                       1547 non-null   float64\n",
      " 54  x3_1990's                       1547 non-null   float64\n",
      " 55  x3_2000's                       1547 non-null   float64\n",
      " 56  x3_2010's                       1547 non-null   float64\n",
      " 57  x0_Distribution Center          1547 non-null   float64\n",
      " 58  x0_Hotel                        1547 non-null   float64\n",
      " 59  x0_K-12 School                  1547 non-null   float64\n",
      " 60  x0_Medical Office               1547 non-null   float64\n",
      " 61  x0_Non-Refrigerated Warehouse   1547 non-null   float64\n",
      " 62  x0_Other - Recreation           1547 non-null   float64\n",
      " 63  x0_Supermarket/Grocery Store    1547 non-null   float64\n",
      " 64  x0_Worship Facility             1547 non-null   float64\n",
      " 65  x0_Restaurant                   1547 non-null   float64\n",
      " 66  Office                          1547 non-null   float64\n",
      " 67  Other                           1547 non-null   float64\n",
      " 68  Retail Store                    1547 non-null   float64\n",
      " 69  infrequent                      1547 non-null   float64\n",
      " 70  Parking                         1547 non-null   float64\n",
      "dtypes: float64(71)\n",
      "memory usage: 858.2 KB\n"
     ]
    }
   ],
   "source": [
    "data_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad1ce2",
   "metadata": {},
   "source": [
    "### 2.1 Préparation des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f57ae700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Séparation Features Target\n",
    "#Target y : TotalGHGEmissions\n",
    "y_2=data_2['log_SiteEnergyUse(kBtu)'].values\n",
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ee0e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>x0_SPS-District K-12</th>\n",
       "      <th>x1_Distribution Center</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Non-Refrigerated Warehouse</th>\n",
       "      <th>x0_Other - Recreation</th>\n",
       "      <th>x0_Supermarket/Grocery Store</th>\n",
       "      <th>x0_Worship Facility</th>\n",
       "      <th>x0_Restaurant</th>\n",
       "      <th>Office</th>\n",
       "      <th>Other</th>\n",
       "      <th>Retail Store</th>\n",
       "      <th>infrequent</th>\n",
       "      <th>Parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423653</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  x0_Campus  x0_NonResidential  \\\n",
       "0                   0.000000        0.0                1.0   \n",
       "1                  13.878913        0.0                1.0   \n",
       "2                  17.585777        0.0                1.0   \n",
       "3                   0.000000        0.0                1.0   \n",
       "4                  15.920004        0.0                1.0   \n",
       "...                      ...        ...                ...   \n",
       "1542                0.000000        0.0                0.0   \n",
       "1543                0.000000        0.0                0.0   \n",
       "1544                0.000000        0.0                0.0   \n",
       "1545                0.000000        0.0                0.0   \n",
       "1546                0.000000        0.0                0.0   \n",
       "\n",
       "      x0_Nonresidential COS  x0_Nonresidential WA  x0_SPS-District K-12  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "1542                    1.0                   0.0                   0.0   \n",
       "1543                    1.0                   0.0                   0.0   \n",
       "1544                    1.0                   0.0                   0.0   \n",
       "1545                    1.0                   0.0                   0.0   \n",
       "1546                    1.0                   0.0                   0.0   \n",
       "\n",
       "      x1_Distribution Center  ...  x0_Non-Refrigerated Warehouse  \\\n",
       "0                        0.0  ...                            0.0   \n",
       "1                        0.0  ...                            0.0   \n",
       "2                        0.0  ...                            0.0   \n",
       "3                        0.0  ...                            0.0   \n",
       "4                        0.0  ...                            0.0   \n",
       "...                      ...  ...                            ...   \n",
       "1542                     0.0  ...                            0.0   \n",
       "1543                     0.0  ...                            0.0   \n",
       "1544                     0.0  ...                            0.0   \n",
       "1545                     0.0  ...                            0.0   \n",
       "1546                     0.0  ...                            0.0   \n",
       "\n",
       "      x0_Other - Recreation  x0_Supermarket/Grocery Store  \\\n",
       "0                  0.000000                           0.0   \n",
       "1                  0.000000                           0.0   \n",
       "2                  0.000000                           0.0   \n",
       "3                  0.000000                           0.0   \n",
       "4                  0.000000                           0.0   \n",
       "...                     ...                           ...   \n",
       "1542               1.000000                           0.0   \n",
       "1543               1.000000                           0.0   \n",
       "1544               0.576347                           0.0   \n",
       "1545               0.485868                           0.0   \n",
       "1546               0.475919                           0.0   \n",
       "\n",
       "      x0_Worship Facility  x0_Restaurant  Office  Other  Retail Store  \\\n",
       "0                     0.0       0.000000     0.0    0.0           0.0   \n",
       "1                     0.0       0.044629     0.0    0.0           0.0   \n",
       "2                     0.0       0.000000     0.0    0.0           0.0   \n",
       "3                     0.0       0.000000     0.0    0.0           0.0   \n",
       "4                     0.0       0.000000     0.0    0.0           0.0   \n",
       "...                   ...            ...     ...    ...           ...   \n",
       "1542                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1543                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1544                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1545                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1546                  0.0       0.000000     0.0    0.0           0.0   \n",
       "\n",
       "      infrequent   Parking  \n",
       "0       0.000000  0.000000  \n",
       "1       0.000000  0.145453  \n",
       "2       0.000000  0.000000  \n",
       "3       0.000000  0.000000  \n",
       "4       0.000000  0.355224  \n",
       "...          ...       ...  \n",
       "1542    0.000000  0.000000  \n",
       "1543    0.000000  0.000000  \n",
       "1544    0.423653  0.000000  \n",
       "1545    0.514132  0.000000  \n",
       "1546    0.524081  0.000000  \n",
       "\n",
       "[1547 rows x 69 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe des Features, on retire les colonnes targets\n",
    "model_2_data=data_2.copy()\n",
    "targets_2=['log_SiteEnergyUse(kBtu)','log_TotalGHGEmissions']\n",
    "model_2_data.drop(targets_2,axis=1, inplace=True)\n",
    "model_2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30ac8fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 69)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2=model_2_data.values\n",
    "X_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281e3bc",
   "metadata": {},
   "source": [
    "#### Standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01561a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04246324,  1.80319003,  0.35194475, ..., -0.31596173,\n",
       "        -0.58677238, -0.43189048],\n",
       "       [-0.04246324,  1.68388254,  0.51427078, ..., -0.31596173,\n",
       "        -0.58677238,  0.8982949 ],\n",
       "       [-0.04246324,  3.55118577,  2.79849165, ..., -0.31596173,\n",
       "        -0.58677238, -0.43189048],\n",
       "       ...,\n",
       "       [-0.04246324, -0.9868208 , -1.60606654, ..., -0.31596173,\n",
       "         0.56912102, -0.43189048],\n",
       "       [-0.04246324, -0.9868208 , -1.53486067, ..., -0.31596173,\n",
       "         0.81598478, -0.43189048],\n",
       "       [-0.04246324, -0.9868208 , -1.26936336, ..., -0.31596173,\n",
       "         0.8431285 , -0.43189048]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardisation des données avec StandardScaler()\n",
    "std_scale = preprocessing.StandardScaler()\n",
    "X_2 = std_scale.fit_transform(X_2)\n",
    "X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca390a",
   "metadata": {},
   "source": [
    "#### Split du jeu de données en données d'entraînement et données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b7b2497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement X_train : (1237, 69)\n",
      "Taille du jeu de test X_test: (310, 69)\n",
      "Taille de y_train : (1237,)\n",
      "Taille de y_test : (310,)\n"
     ]
    }
   ],
   "source": [
    "# Split du jeu de données en données d'entraînement et données de test\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = model_selection.train_test_split(X_2, y_2, test_size=0.2) # 20% des données dans le jeu de test\n",
    "#X_train_2, X_test_2, y_train_2, y_test_2 = model_selection.train_test_split(X_2, y_2, test_size=0.2, shuffle=False) # 30% des données dans le jeu de test\n",
    "print(\"Taille du jeu d'entraînement X_train : \"+ str(X_train_2.shape))\n",
    "print(\"Taille du jeu de test X_test: \"+ str(X_test_2.shape))\n",
    "print(\"Taille de y_train : \"+ str(y_train_2.shape))\n",
    "print(\"Taille de y_test : \"+ str(y_test_2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e82ac",
   "metadata": {},
   "source": [
    "## 2.2 Approche Naïve : DummyRegrossor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af0620da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.90\n",
      "R2 : -0.01\n"
     ]
    }
   ],
   "source": [
    "#Strategy : mean\n",
    "dum_reg_2 = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entraînement\n",
    "dum_reg_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_dum_2 = dum_reg_2.predict(X_test_2)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_2, y_pred_dum_2)) ))\n",
    "print(\"R2 : {:.2f}\".format(dum_reg_2.score(X_test_2,y_test_2) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ffaa7",
   "metadata": {},
   "source": [
    "## 2.3 ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "546bad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.136e+02, tolerance: 3.390e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.058e+02, tolerance: 3.573e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.252e+02, tolerance: 3.631e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.962e+02, tolerance: 3.518e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.278e+02, tolerance: 3.563e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.940e+01, tolerance: 3.390e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.496e+01, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+01, tolerance: 3.631e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.921e+02, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.928e+02, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e+01, tolerance: 3.390e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e+01, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+01, tolerance: 3.631e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+02, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+02, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+00, tolerance: 3.390e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.279e+00, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+01, tolerance: 3.631e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+02, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+02, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.784e-01, tolerance: 3.390e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+00, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.610e+00, tolerance: 3.631e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+02, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+02, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+00, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.028e+00, tolerance: 3.631e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.013e+01, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.302e+01, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+00, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.653e+00, tolerance: 3.631e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.567e+01, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.300e+01, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+00, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+00, tolerance: 3.631e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.669e+01, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.779e+01, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e+00, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.271e-01, tolerance: 3.631e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.149e+01, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.601e+01, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.527e-01, tolerance: 3.390e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 3.573e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.925e+01, tolerance: 3.518e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.658e+01, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.149e+02, tolerance: 3.390e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.074e+02, tolerance: 3.573e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.265e+02, tolerance: 3.631e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.975e+02, tolerance: 3.518e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.292e+02, tolerance: 3.563e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.900e-01, tolerance: 3.563e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.271e+02, tolerance: 3.390e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.198e+02, tolerance: 3.573e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.381e+02, tolerance: 3.631e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.093e+02, tolerance: 3.518e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.418e+02, tolerance: 3.563e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.162e+02, tolerance: 3.390e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+02, tolerance: 3.573e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.281e+02, tolerance: 3.631e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.012e+02, tolerance: 3.518e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.337e+02, tolerance: 3.563e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.912e+02, tolerance: 3.390e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.877e+02, tolerance: 3.573e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.159e+02, tolerance: 3.631e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.948e+02, tolerance: 3.518e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.140e+02, tolerance: 3.563e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+03, tolerance: 3.390e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+03, tolerance: 3.573e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+03, tolerance: 3.631e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+03, tolerance: 3.518e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+03, tolerance: 3.563e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e+03, tolerance: 3.390e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.750e+03, tolerance: 3.573e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.779e+03, tolerance: 3.631e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+03, tolerance: 3.518e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+03, tolerance: 3.563e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'l1_ratio': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef de régularisation. Si égale à 0, équivaut à régresison linéaire simple\n",
    "              \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}#L1 ratio , si égal à 1 équivaut à un Lasso, si égal 0 à un Ridge\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "elastic_net_grid_2 = model_selection.GridSearchCV(estimator = linear_model.ElasticNet(),  # ElasticNet regression\n",
    "                      param_grid = parameters,  # hyperparamètres à tester\n",
    "                    scoring = score,  # score à optimiser R2\n",
    "\n",
    "                     # scoring = 'neg_root_mean_squared_error',  # score à optimiserRMSE\n",
    "                      cv=5, # nombre de folds de validation croisée\n",
    "                      verbose=0\n",
    "                     )\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "elastic_net_grid_2.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac5aabc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les Meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'l1_ratio': 0.9}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les hyperparamètres optimaux\n",
    "print(\"Les meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net:\")\n",
    "elastic_net_grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5db2a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs parametres\n",
    "y_el_net_pred_2=elastic_net_grid_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82a4b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.97\n",
      "R2 test : 0.74\n",
      "R2 train : 0.7291529901702998\n",
      "Temps d'execution 0.012879537173679899 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Elastic Net sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_2, y_el_net_pred_2)) ))\n",
    "print(\"R2 test : {:.2f}\".format(elastic_net_grid_2.score(X_test_2,y_test_2) ))\n",
    "print(\"R2 train : \" + str(elastic_net_grid_2.best_score_))\n",
    "print(\"Temps d'execution \"+ str(elastic_net_grid_2.cv_results_['mean_fit_time'].mean())+\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fee28c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients des features dans le modèle\n",
    "coefficients_el_net = abs(elastic_net_grid_2.best_estimator_.coef_)\n",
    "liste_coefs_el_net = pd.concat((pd.DataFrame(model_2_data.columns, columns = ['Features']), \n",
    "                      pd.DataFrame(coefficients_el_net, columns = ['Coefficient'])), axis = 1).sort_values(by='Coefficient', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "299e29f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Elastic Net - Consommation - Importance des 15 premières Features')\n",
    "sns.barplot(y = liste_coefs_el_net['Features'].head(15),\n",
    "            x = liste_coefs_el_net['Coefficient'].head(15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13c51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0b82c30",
   "metadata": {},
   "source": [
    "## 2.4 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40a105a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=10;, score=0.690 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=10;, score=0.677 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=10;, score=0.645 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=10;, score=0.677 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=10;, score=0.687 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=50;, score=0.718 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=50;, score=0.686 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=50;, score=0.679 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=50;, score=0.670 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=50;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=100;, score=0.725 total time=   0.3s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=100;, score=0.682 total time=   0.3s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=100;, score=0.689 total time=   0.3s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=100;, score=0.671 total time=   0.3s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=100;, score=0.716 total time=   0.3s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=300;, score=0.728 total time=   1.2s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=300;, score=0.685 total time=   1.2s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=300;, score=0.689 total time=   1.2s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=300;, score=0.680 total time=   1.2s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=300;, score=0.720 total time=   1.2s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=500;, score=0.727 total time=   2.1s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=500;, score=0.682 total time=   2.1s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=500;, score=0.688 total time=   2.1s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=500;, score=0.683 total time=   2.1s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=500;, score=0.720 total time=   2.1s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=10;, score=0.719 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=10;, score=0.659 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=10;, score=0.644 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=10;, score=0.665 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=10;, score=0.703 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=50;, score=0.734 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=50;, score=0.680 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=50;, score=0.670 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=50;, score=0.691 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=50;, score=0.717 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=100;, score=0.728 total time=   0.2s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=100;, score=0.678 total time=   0.2s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=100;, score=0.669 total time=   0.2s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=100;, score=0.689 total time=   0.2s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=100;, score=0.715 total time=   0.2s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=300;, score=0.730 total time=   0.9s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=300;, score=0.677 total time=   0.8s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=300;, score=0.677 total time=   0.8s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=300;, score=0.687 total time=   0.9s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=300;, score=0.714 total time=   0.9s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=500;, score=0.733 total time=   1.5s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=500;, score=0.673 total time=   1.5s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=500;, score=0.670 total time=   1.5s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=500;, score=0.688 total time=   1.5s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=500;, score=0.713 total time=   1.5s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=10;, score=0.717 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=10;, score=0.631 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=10;, score=0.616 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=10;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=10;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=50;, score=0.733 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=50;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=50;, score=0.647 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=50;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=50;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=100;, score=0.726 total time=   0.2s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=100;, score=0.658 total time=   0.2s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=100;, score=0.655 total time=   0.2s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=100;, score=0.679 total time=   0.2s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=100;, score=0.688 total time=   0.2s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=300;, score=0.733 total time=   0.7s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=300;, score=0.658 total time=   0.7s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=300;, score=0.652 total time=   0.7s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=300;, score=0.683 total time=   0.7s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=300;, score=0.692 total time=   0.7s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=500;, score=0.731 total time=   1.3s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=500;, score=0.656 total time=   1.3s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=500;, score=0.652 total time=   1.3s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=500;, score=0.683 total time=   1.3s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=500;, score=0.691 total time=   1.3s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=10;, score=0.695 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=10;, score=0.622 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=10;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=10;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=10;, score=0.666 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=50;, score=0.707 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=50;, score=0.626 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=50;, score=0.612 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=50;, score=0.663 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=50;, score=0.660 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=100;, score=0.704 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=100;, score=0.630 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=100;, score=0.612 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=100;, score=0.660 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=100;, score=0.661 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=300;, score=0.705 total time=   0.6s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=300;, score=0.628 total time=   0.6s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=300;, score=0.614 total time=   0.6s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=300;, score=0.665 total time=   0.6s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=300;, score=0.663 total time=   0.6s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=500;, score=0.704 total time=   1.0s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=500;, score=0.624 total time=   1.0s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=500;, score=0.615 total time=   1.0s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=500;, score=0.663 total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END min_samples_leaf=10, n_estimators=500;, score=0.665 total time=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'min_samples_leaf': [1, 3, 5, 10],\n",
       "                         'n_estimators': [10, 50, 100, 300, 500]},\n",
       "             scoring='r2', verbose=5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\n",
    "    'n_estimators' : [10,50,100,300,500], #nombre d'arbres de décision\n",
    "    'min_samples_leaf' : [1,3,5,10], #nombre de feuilles minimales dans un noeud\n",
    "    #'max_features': ['auto', 'sqrt'] #nombre de features observées pour chaque arbre\n",
    "}\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "\n",
    "random_forest_grid_2 = model_selection.GridSearchCV(RandomForestRegressor(),\n",
    "                               param_grid = parameters,\n",
    "                               scoring=score,\n",
    "                              verbose=5,\n",
    "                               cv=5)\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "random_forest_grid_2.fit(X_train_2, y_train_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed29ea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les Meilleurs hyperparamètres pour le modèle non linéaire Random Forest \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 1, 'n_estimators': 300}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les hyperparamètres optimaux\n",
    "print(\"Les meilleurs hyperparamètres pour le modèle non linéaire Random Forest \")\n",
    "random_forest_grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bded1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs parametres\n",
    "y_rand_for_pred_2 = random_forest_grid_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2d510f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.01\n",
      "R2 : 0.72\n",
      "R2 train : 0.7002236177951519\n",
      "Temps d'execution :0.5872884631156922 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Random Forest sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_2, y_rand_for_pred_2)) ))\n",
    "print(\"R2 : {:.2f}\".format(random_forest_grid_2.score(X_test_2,y_test_2) ))\n",
    "print(\"R2 train : \"+ str(random_forest_grid_2.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (random_forest_grid_2.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4062b5a",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaaf31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients des features dans le modèle\n",
    "coefficients_RF = abs(random_forest_grid_2.best_estimator_.feature_importances_)\n",
    "liste_coefs_RF = pd.concat((pd.DataFrame(model_2_data.columns, columns = ['Features']), \n",
    "                      pd.DataFrame(coefficients_RF, columns = ['Coefficient'])), axis = 1).sort_values(by='Coefficient', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f0070f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('RandomForest - Consommation - Importance des 15 premières Features')\n",
    "sns.barplot(y = liste_coefs_RF['Features'].head(15),\n",
    "            x = liste_coefs_RF['Coefficient'].head(15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "571cfdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Iter 1 - Elastic Net\n",
      "RMSE : 1.06\n",
      "R2 test : 0.70\n",
      "R2 train : 0.7424963253819621\n",
      "Temps d'execution :0.01250805105481829 s\n",
      "\n",
      "#### Iter 1 - Random Forest\n",
      "RMSE : 1.11\n",
      "R2 test : 0.67\n",
      "R2 train : 0.7044477126452161\n",
      "Temps d'execution :0.46115902185440066 s\n",
      "\n",
      "#### Iter 2 - Elastic Net\n",
      "RMSE : 0.97\n",
      "R2 test : 0.74\n",
      "R2 train : 0.7291529901702998\n",
      "Temps d'execution 0.012879537173679899 s\n",
      "\n",
      "#### Iter 2 - Random Forest\n",
      "RMSE : 1.01\n",
      "R2 test : 0.72\n",
      "R2 train : 0.7002236177951519\n",
      "Temps d'execution :0.5872884631156922 s\n"
     ]
    }
   ],
   "source": [
    "# Iter 1 - Elastic Net\n",
    "print(\"#### Iter 1 - Elastic Net\")\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_el_net_pred)) ))\n",
    "print(\"R2 test : {:.2f}\".format(elastic_net_grid.score(X_test,y_test) ))\n",
    "print(\"R2 train : \" + str(elastic_net_grid.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (elastic_net_grid.cv_results_['mean_fit_time'].mean())+ \" s\" )\n",
    "print()\n",
    "\n",
    "# Iter 1 - Random Forest\n",
    "print(\"#### Iter 1 - Random Forest\")\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_rand_for_pred)) ))\n",
    "print(\"R2 test : {:.2f}\".format(random_forest_grid.score(X_test,y_test) ))\n",
    "print(\"R2 train : \"+ str(random_forest_grid.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (random_forest_grid.cv_results_['mean_fit_time'].mean())+ \" s\" )\n",
    "print()\n",
    "\n",
    "# Iter 2 - Elastic Net\n",
    "print(\"#### Iter 2 - Elastic Net\")\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_2, y_el_net_pred_2)) ))\n",
    "print(\"R2 test : {:.2f}\".format(elastic_net_grid_2.score(X_test_2,y_test_2) ))\n",
    "print(\"R2 train : \" + str(elastic_net_grid_2.best_score_))\n",
    "print(\"Temps d'execution \"+ str(elastic_net_grid_2.cv_results_['mean_fit_time'].mean())+\" s\")\n",
    "print()\n",
    "\n",
    "# Iter 2 - Random Forest\n",
    "print(\"#### Iter 2 - Random Forest\")\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_2, y_rand_for_pred_2)) ))\n",
    "print(\"R2 test : {:.2f}\".format(random_forest_grid_2.score(X_test_2,y_test_2) ))\n",
    "print(\"R2 train : \"+ str(random_forest_grid_2.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (random_forest_grid_2.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5057a027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
