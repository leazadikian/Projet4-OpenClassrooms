{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee400ca",
   "metadata": {},
   "source": [
    "Léa ZADIKIAN - Novembre 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3a0a5",
   "metadata": {},
   "source": [
    "# Projet n°4 : Anticipez les besoins en consommation de bâtiments\n",
    "# Notebook prédiction des émission de CO2\n",
    "La prédiction des émissions est réalisée dans un Notebook séparé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a448f1",
   "metadata": {},
   "source": [
    "Données et définition des variables : https://data.seattle.gov/dataset/2016-Building-Energy-Benchmarking/2bpz-gwpy\n",
    "\n",
    "**Objectif** : prédire les émissions de CO2 et la consommation totale d’énergie de bâtiments non destinés à l’habitation de la ville de Seattle, pour lesquels elles n’ont pas encore été mesurées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a656425",
   "metadata": {},
   "source": [
    "# Sommaire :\n",
    "\n",
    "<a href=\"#C1\">1. Première itération</a>\n",
    "\n",
    "1.1 Import et préparation des données\n",
    "- Importation du jeu de données cleanné\n",
    "- Préparation des données : standardisation, séparation jeu de d'entraînement / jeu de test\n",
    "\n",
    "1.2 Approche naïve : Dummy regressor\n",
    "    \n",
    "1.3 Modèle linéaire : Elastic Net\n",
    "    \n",
    "1.4. Modèle non linéaire : Random Forest\n",
    "    \n",
    "<a href=\"#C2\">2.Deuxième itération </a>\n",
    "\n",
    "2.1 Import et préparation des données\n",
    "\n",
    "2.2 Approche naïve : Dummy regressor\n",
    "\n",
    "2.3 Modèle linéaire : Elastic Net\n",
    "\n",
    "2.4 Modèle non linéaire : Random Forest\n",
    "\n",
    "<a href=\"#C3\">3.Troisième itération : intérêt de ENERGYSTAR Score</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f856ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import kernel_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05eb4c",
   "metadata": {},
   "source": [
    "# <a name=\"C1\">1. Première itération </a>\n",
    "## 1.1 Import et préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567e309",
   "metadata": {},
   "source": [
    "### 1.1.1 Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335b796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>log_TotalGHGEmissions</th>\n",
       "      <th>log_SiteEnergyUse(kBtu)</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_1920's</th>\n",
       "      <th>x3_1930's</th>\n",
       "      <th>x3_1940's</th>\n",
       "      <th>x3_1950's</th>\n",
       "      <th>x3_1960's</th>\n",
       "      <th>x3_1970's</th>\n",
       "      <th>x3_1980's</th>\n",
       "      <th>x3_1990's</th>\n",
       "      <th>x3_2000's</th>\n",
       "      <th>x3_2010's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.971429</td>\n",
       "      <td>22.784838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>8.213639</td>\n",
       "      <td>22.999884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>11.029480</td>\n",
       "      <td>26.113208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.167067</td>\n",
       "      <td>22.695954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>8.983022</td>\n",
       "      <td>23.756602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.414812</td>\n",
       "      <td>19.830099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.051807</td>\n",
       "      <td>19.857989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.810829</td>\n",
       "      <td>22.459114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.530445</td>\n",
       "      <td>19.456579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.401562</td>\n",
       "      <td>20.136833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  log_TotalGHGEmissions  log_SiteEnergyUse(kBtu)  \\\n",
       "0                   0.000000               7.971429                22.784838   \n",
       "1                  13.878913               8.213639                22.999884   \n",
       "2                  17.585777              11.029480                26.113208   \n",
       "3                   0.000000               8.167067                22.695954   \n",
       "4                  15.920004               8.983022                23.756602   \n",
       "...                      ...                    ...                      ...   \n",
       "1542                0.000000               4.414812                19.830099   \n",
       "1543                0.000000               5.051807                19.857989   \n",
       "1544                0.000000               7.810829                22.459114   \n",
       "1545                0.000000               4.530445                19.456579   \n",
       "1546                0.000000               5.401562                20.136833   \n",
       "\n",
       "      x0_Campus  x0_NonResidential  x0_Nonresidential COS  \\\n",
       "0           0.0                1.0                    0.0   \n",
       "1           0.0                1.0                    0.0   \n",
       "2           0.0                1.0                    0.0   \n",
       "3           0.0                1.0                    0.0   \n",
       "4           0.0                1.0                    0.0   \n",
       "...         ...                ...                    ...   \n",
       "1542        0.0                0.0                    1.0   \n",
       "1543        0.0                0.0                    1.0   \n",
       "1544        0.0                0.0                    1.0   \n",
       "1545        0.0                0.0                    1.0   \n",
       "1546        0.0                0.0                    1.0   \n",
       "\n",
       "      x0_Nonresidential WA  ...  x3_1920's  x3_1930's  x3_1940's  x3_1950's  \\\n",
       "0                      0.0  ...        1.0        0.0        0.0        0.0   \n",
       "1                      0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2                      0.0  ...        0.0        0.0        0.0        0.0   \n",
       "3                      0.0  ...        1.0        0.0        0.0        0.0   \n",
       "4                      0.0  ...        0.0        0.0        0.0        0.0   \n",
       "...                    ...  ...        ...        ...        ...        ...   \n",
       "1542                   0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1543                   0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1544                   0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1545                   0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1546                   0.0  ...        0.0        1.0        0.0        0.0   \n",
       "\n",
       "      x3_1960's  x3_1970's  x3_1980's  x3_1990's  x3_2000's  x3_2010's  \n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1           0.0        0.0        0.0        1.0        0.0        0.0  \n",
       "2           1.0        0.0        0.0        0.0        0.0        0.0  \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "4           0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "1542        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1543        0.0        0.0        0.0        0.0        1.0        0.0  \n",
       "1544        0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "1545        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1546        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[1547 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lecture et affichage du fichier '2016_Building_Energy_Benchmarking_clean_model_1.csv'\n",
    "data=pd.read_csv('2016_Building_Energy_Benchmarking_clean_model_1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece82f6",
   "metadata": {},
   "source": [
    "### 1.1.2 Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ce633",
   "metadata": {},
   "source": [
    "#### Séparation features / tagets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c331f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target y : TotalGHGEmissions\n",
    "y=data['log_TotalGHGEmissions'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efb90c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>x0_SPS-District K-12</th>\n",
       "      <th>x1_Distribution Center</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_1920's</th>\n",
       "      <th>x3_1930's</th>\n",
       "      <th>x3_1940's</th>\n",
       "      <th>x3_1950's</th>\n",
       "      <th>x3_1960's</th>\n",
       "      <th>x3_1970's</th>\n",
       "      <th>x3_1980's</th>\n",
       "      <th>x3_1990's</th>\n",
       "      <th>x3_2000's</th>\n",
       "      <th>x3_2010's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  x0_Campus  x0_NonResidential  \\\n",
       "0                   0.000000        0.0                1.0   \n",
       "1                  13.878913        0.0                1.0   \n",
       "2                  17.585777        0.0                1.0   \n",
       "3                   0.000000        0.0                1.0   \n",
       "4                  15.920004        0.0                1.0   \n",
       "...                      ...        ...                ...   \n",
       "1542                0.000000        0.0                0.0   \n",
       "1543                0.000000        0.0                0.0   \n",
       "1544                0.000000        0.0                0.0   \n",
       "1545                0.000000        0.0                0.0   \n",
       "1546                0.000000        0.0                0.0   \n",
       "\n",
       "      x0_Nonresidential COS  x0_Nonresidential WA  x0_SPS-District K-12  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "1542                    1.0                   0.0                   0.0   \n",
       "1543                    1.0                   0.0                   0.0   \n",
       "1544                    1.0                   0.0                   0.0   \n",
       "1545                    1.0                   0.0                   0.0   \n",
       "1546                    1.0                   0.0                   0.0   \n",
       "\n",
       "      x1_Distribution Center  ...  x3_1920's  x3_1930's  x3_1940's  x3_1950's  \\\n",
       "0                        0.0  ...        1.0        0.0        0.0        0.0   \n",
       "1                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "3                        0.0  ...        1.0        0.0        0.0        0.0   \n",
       "4                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "...                      ...  ...        ...        ...        ...        ...   \n",
       "1542                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1543                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1544                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1545                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1546                     0.0  ...        0.0        1.0        0.0        0.0   \n",
       "\n",
       "      x3_1960's  x3_1970's  x3_1980's  x3_1990's  x3_2000's  x3_2010's  \n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1           0.0        0.0        0.0        1.0        0.0        0.0  \n",
       "2           1.0        0.0        0.0        0.0        0.0        0.0  \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "4           0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "1542        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1543        0.0        0.0        0.0        0.0        1.0        0.0  \n",
       "1544        0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "1545        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1546        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[1547 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe des features, on retire les colonnes correspondant aux 2 targets\n",
    "model_1_data=data.copy()\n",
    "targets=['log_SiteEnergyUse(kBtu)','log_TotalGHGEmissions']\n",
    "model_1_data.drop(targets,axis=1, inplace=True)\n",
    "model_1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b807f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 55)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Récupération des valeurs des features\n",
    "X=model_1_data.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f51175",
   "metadata": {},
   "source": [
    "#### Standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba1054d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04246324,  1.80319003,  0.35194475, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324,  1.68388254,  0.51427078, ...,  3.0405646 ,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324,  3.55118577,  2.79849165, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       ...,\n",
       "       [-0.04246324, -0.9868208 , -1.60606654, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324, -0.9868208 , -1.53486067, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324, -0.9868208 , -1.26936336, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardisation des données avec StandardScaler()\n",
    "std_scale = preprocessing.StandardScaler()\n",
    "X= std_scale.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c59546b",
   "metadata": {},
   "source": [
    "#### Split du jeu de données en données d'entraînement et données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40e2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement X_train : (1237, 55)\n",
      "Taille du jeu de test X_test: (310, 55)\n",
      "Taille de y_train : (1237,)\n",
      "Taille de y_test : (310,)\n"
     ]
    }
   ],
   "source": [
    "# Split du jeu de données en données d'entraînement et données de test\n",
    "#X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, shuffle=False) # 20% des données dans le jeu de test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2) # 20% des données dans le jeu de test\n",
    "print(\"Taille du jeu d'entraînement X_train : \"+ str(X_train.shape))\n",
    "print(\"Taille du jeu de test X_test: \"+ str(X_test.shape))\n",
    "print(\"Taille de y_train : \"+ str(y_train.shape))\n",
    "print(\"Taille de y_test : \"+ str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e9b280",
   "metadata": {},
   "source": [
    "# 1.2  Approche Naïve : DummyRegressor\n",
    "Regressor that makes predictions using simple rules.This regressor is useful as a simple baseline to compare with other (real) regressors.\n",
    "Strategy to use to generate predictions : {“mean”, “median”, “quantile”, “constant”}, default=”mean”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3a85f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.836896351319058"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d499af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 2.13\n",
      "R2 : -0.00\n"
     ]
    }
   ],
   "source": [
    "#Strategy : mean\n",
    "dum_reg = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entraînement\n",
    "dum_reg.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_dum = dum_reg.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_pred_dum)) ))\n",
    "print(\"R2 : {:.2f}\".format(dum_reg.score(X_test,y_test) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab897f1",
   "metadata": {},
   "source": [
    "Comme attendu, on trouve R2=0. R2 compare la performence du moyenne par rapport une prédiction par la moyenne, hors notre modèle est une prédiction par la moyenne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0697579",
   "metadata": {},
   "source": [
    "## 1.3. Régression linéaire Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468f090",
   "metadata": {},
   "source": [
    "ElasticNet is a linear regression model trained with both l1 and l2 norm regularization of the coefficients. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of  and  using the l1_ratio parameter.\n",
    "\n",
    "Elastic-net is useful when there are multiple features that are correlated with one another. Lasso is likely to pick one of these at random, while elastic-net is likely to pick both.\n",
    "\n",
    "A practical advantage of trading-off between Lasso and Ridge is that it allows Elastic-Net to inherit some of Ridge’s stability under rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ac8648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.794e+02, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.017e+02, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e+02, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.037e+02, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.249e+02, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.578e+02, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.548e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+02, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+02, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+02, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.355e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.817e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.942e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.422e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.067e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.086e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.817e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.037e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.790e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.650e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.066e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.662e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.622e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.725e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e+01, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.335e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.820e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+01, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+01, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.146e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.692e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e+01, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.020e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.806e+02, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.029e+02, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.976e+02, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.049e+02, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.262e+02, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.375e+00, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.477e+00, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.032e+00, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.733e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.784e-01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+00, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.895e+00, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.714e+00, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.711e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.982e-01, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.652e-01, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.889e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.242e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.585e-01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.925e+02, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.149e+02, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.089e+02, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.168e+02, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.385e+02, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+02, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+03, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+03, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+03, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.414e+02, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+03, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+03, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+03, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+03, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+03, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+03, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+03, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+03, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+03, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+03, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+03, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+03, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+03, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+03, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+03, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats de la validation croisée :\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.0}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.1}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.2}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.4}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.5}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.8}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.0001, 'l1_ratio': 0.9}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.001, 'l1_ratio': 0.1}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.001, 'l1_ratio': 0.2}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.001, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.001, 'l1_ratio': 0.4}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.001, 'l1_ratio': 0.5}\n",
      "r2 = 0.543 (+/-0.105) for {'alpha': 0.001, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.543 (+/-0.104) for {'alpha': 0.001, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.543 (+/-0.104) for {'alpha': 0.001, 'l1_ratio': 0.8}\n",
      "r2 = 0.543 (+/-0.104) for {'alpha': 0.001, 'l1_ratio': 0.9}\n",
      "r2 = 0.543 (+/-0.104) for {'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "r2 = 0.544 (+/-0.103) for {'alpha': 0.01, 'l1_ratio': 0.1}\n",
      "r2 = 0.544 (+/-0.102) for {'alpha': 0.01, 'l1_ratio': 0.2}\n",
      "r2 = 0.545 (+/-0.102) for {'alpha': 0.01, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.545 (+/-0.101) for {'alpha': 0.01, 'l1_ratio': 0.4}\n",
      "r2 = 0.545 (+/-0.101) for {'alpha': 0.01, 'l1_ratio': 0.5}\n",
      "r2 = 0.546 (+/-0.100) for {'alpha': 0.01, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.546 (+/-0.099) for {'alpha': 0.01, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.546 (+/-0.099) for {'alpha': 0.01, 'l1_ratio': 0.8}\n",
      "r2 = 0.546 (+/-0.098) for {'alpha': 0.01, 'l1_ratio': 0.9}\n",
      "r2 = 0.539 (+/-0.093) for {'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "r2 = 0.540 (+/-0.089) for {'alpha': 0.1, 'l1_ratio': 0.1}\n",
      "r2 = 0.540 (+/-0.085) for {'alpha': 0.1, 'l1_ratio': 0.2}\n",
      "r2 = 0.537 (+/-0.080) for {'alpha': 0.1, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.534 (+/-0.076) for {'alpha': 0.1, 'l1_ratio': 0.4}\n",
      "r2 = 0.531 (+/-0.072) for {'alpha': 0.1, 'l1_ratio': 0.5}\n",
      "r2 = 0.527 (+/-0.069) for {'alpha': 0.1, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.522 (+/-0.067) for {'alpha': 0.1, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.516 (+/-0.065) for {'alpha': 0.1, 'l1_ratio': 0.8}\n",
      "r2 = 0.511 (+/-0.064) for {'alpha': 0.1, 'l1_ratio': 0.9}\n",
      "r2 = 0.433 (+/-0.058) for {'alpha': 1, 'l1_ratio': 0.0}\n",
      "r2 = 0.389 (+/-0.045) for {'alpha': 1, 'l1_ratio': 0.1}\n",
      "r2 = 0.331 (+/-0.037) for {'alpha': 1, 'l1_ratio': 0.2}\n",
      "r2 = 0.283 (+/-0.032) for {'alpha': 1, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = 0.256 (+/-0.028) for {'alpha': 1, 'l1_ratio': 0.4}\n",
      "r2 = 0.243 (+/-0.026) for {'alpha': 1, 'l1_ratio': 0.5}\n",
      "r2 = 0.230 (+/-0.026) for {'alpha': 1, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = 0.216 (+/-0.025) for {'alpha': 1, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = 0.197 (+/-0.024) for {'alpha': 1, 'l1_ratio': 0.8}\n",
      "r2 = 0.175 (+/-0.023) for {'alpha': 1, 'l1_ratio': 0.9}\n",
      "r2 = 0.147 (+/-0.021) for {'alpha': 10, 'l1_ratio': 0.0}\n",
      "r2 = 0.012 (+/-0.013) for {'alpha': 10, 'l1_ratio': 0.1}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 10, 'l1_ratio': 0.2}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 10, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 10, 'l1_ratio': 0.4}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 10, 'l1_ratio': 0.5}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 10, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 10, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 10, 'l1_ratio': 0.8}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 10, 'l1_ratio': 0.9}\n",
      "r2 = 0.016 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.0}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.1}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.2}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.30000000000000004}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.4}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.5}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.6000000000000001}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.7000000000000001}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.8}\n",
      "r2 = -0.005 (+/-0.012) for {'alpha': 100, 'l1_ratio': 0.9}\n"
     ]
    }
   ],
   "source": [
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef de régularisation. Si égale à 0, équivaut à régresison linéaire simple\n",
    "              \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}#L1 ratio , si égal à 1 équivaut à un Lasso, si égal 0 à un Ridge\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "elastic_net_grid = model_selection.GridSearchCV(estimator = linear_model.ElasticNet(),  # ElasticNet regression\n",
    "                      param_grid = parameters,  # hyperparamètres à tester\n",
    "                    scoring = score,  # score à optimiser R2\n",
    "\n",
    "                      #scoring = 'neg_root_mean_squared_error',  # score à optimiserRMSE\n",
    "                      cv=5, # nombre de folds de validation croisée\n",
    "                      verbose=0\n",
    "                     )\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "elastic_net_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(\n",
    "        elastic_net_grid.cv_results_['mean_test_score'], # score moyen\n",
    "        elastic_net_grid.cv_results_['std_test_score'],  # écart-type du score\n",
    "        elastic_net_grid.cv_results_['params']           # valeur de l'hyperparamètre\n",
    "):\n",
    "\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(score,\n",
    "                                                   mean,\n",
    "                                                   std*2,\n",
    "                                                   params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd1c3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03639956, 0.03539844, 0.03539858, 0.0353991 , 0.03519821,\n",
       "        0.03499765, 0.03519902, 0.0351985 , 0.03539824, 0.0353992 ,\n",
       "        0.03539834, 0.03459888, 0.03359861, 0.03199935, 0.02919879,\n",
       "        0.02479887, 0.01799951, 0.01520009, 0.01560001, 0.01579947,\n",
       "        0.03499918, 0.00599818, 0.00499949, 0.00439911, 0.00359898,\n",
       "        0.00379968, 0.00300007, 0.00199909, 0.00140009, 0.00180044,\n",
       "        0.03559904, 0.00080023, 0.00100021, 0.00100007, 0.00080009,\n",
       "        0.00079994, 0.00099998, 0.        , 0.00099998, 0.00099998,\n",
       "        0.03539748, 0.00100064, 0.00100002, 0.00039992, 0.00019999,\n",
       "        0.0006    , 0.00039992, 0.00039997, 0.00079999, 0.0006    ,\n",
       "        0.03579884, 0.00019999, 0.0006    , 0.0006    , 0.00019994,\n",
       "        0.00039997, 0.00079999, 0.00019999, 0.00040007, 0.0006    ,\n",
       "        0.03579855, 0.00079999, 0.00019999, 0.00040007, 0.00079999,\n",
       "        0.00019994, 0.00040002, 0.00059996, 0.00040007, 0.00019994]),\n",
       " 'std_fit_time': array([3.82566883e-03, 2.93855184e-03, 3.38299812e-03, 2.93888312e-03,\n",
       "        3.12367204e-03, 3.28634384e-03, 3.12429174e-03, 3.12455449e-03,\n",
       "        3.38253015e-03, 3.38286827e-03, 3.38278654e-03, 3.20050725e-03,\n",
       "        2.41589750e-03, 3.03352796e-03, 5.15366579e-03, 4.26147977e-03,\n",
       "        4.38144124e-03, 6.04650574e-03, 7.22775208e-03, 1.11426716e-02,\n",
       "        3.68827459e-03, 6.32938050e-04, 1.09623643e-03, 7.99871548e-04,\n",
       "        8.00753130e-04, 7.48200929e-04, 8.94415692e-04, 6.32259755e-04,\n",
       "        4.90000393e-04, 3.99661758e-04, 3.19944923e-03, 4.00114216e-04,\n",
       "        3.16297988e-07, 2.86102295e-07, 4.00042715e-04, 3.99971037e-04,\n",
       "        1.78416128e-07, 0.00000000e+00, 1.78416128e-07, 9.53674316e-08,\n",
       "        3.38247911e-03, 1.31454933e-06, 1.90734863e-07, 4.89804047e-04,\n",
       "        3.99971008e-04, 4.89901382e-04, 4.89804047e-04, 4.89862464e-04,\n",
       "        3.99994889e-04, 4.89901591e-04, 3.42894008e-03, 3.99971008e-04,\n",
       "        4.89901382e-04, 4.89901475e-04, 3.99875641e-04, 4.89862441e-04,\n",
       "        3.99994918e-04, 3.99971008e-04, 4.89979265e-04, 4.89901382e-04,\n",
       "        3.05859466e-03, 3.99994889e-04, 3.99971008e-04, 4.89979242e-04,\n",
       "        3.99994861e-04, 3.99875641e-04, 4.89920847e-04, 4.89862464e-04,\n",
       "        4.89979242e-04, 3.99875641e-04]),\n",
       " 'mean_score_time': array([0.00020018, 0.00020041, 0.00040092, 0.00060129, 0.00060139,\n",
       "        0.00060124, 0.0004004 , 0.00040092, 0.        , 0.00040078,\n",
       "        0.        , 0.00020041, 0.00020051, 0.        , 0.00040059,\n",
       "        0.00020008, 0.00060005, 0.00019994, 0.        , 0.00040054,\n",
       "        0.00060039, 0.00020046, 0.        , 0.00040064, 0.00040073,\n",
       "        0.        , 0.00060034, 0.00040064, 0.00020008, 0.00019984,\n",
       "        0.00040097, 0.00020003, 0.00039983, 0.00039988, 0.00040002,\n",
       "        0.00020003, 0.        , 0.00080004, 0.        , 0.        ,\n",
       "        0.00060129, 0.        , 0.        , 0.00060005, 0.        ,\n",
       "        0.00040002, 0.        , 0.00020013, 0.        , 0.00019999,\n",
       "        0.00020022, 0.0004004 , 0.00020008, 0.        , 0.00040002,\n",
       "        0.00040002, 0.        , 0.00019999, 0.00019999, 0.00019999,\n",
       "        0.00040083, 0.        , 0.00020003, 0.00039997, 0.        ,\n",
       "        0.00019999, 0.00019999, 0.00019999, 0.00019999, 0.00040007]),\n",
       " 'std_score_time': array([0.00040035, 0.00040083, 0.00049103, 0.00049095, 0.00049103,\n",
       "        0.00049091, 0.00049039, 0.00049103, 0.        , 0.00049086,\n",
       "        0.        , 0.00040083, 0.00040102, 0.        , 0.00049062,\n",
       "        0.00040016, 0.00048994, 0.00039988, 0.        , 0.00049056,\n",
       "        0.00049021, 0.00040092, 0.        , 0.00049068, 0.0004908 ,\n",
       "        0.        , 0.00049017, 0.00049068, 0.00040016, 0.00039968,\n",
       "        0.00049109, 0.00040007, 0.00048969, 0.00048975, 0.00048992,\n",
       "        0.00040007, 0.        , 0.00040002, 0.        , 0.        ,\n",
       "        0.00049095, 0.        , 0.        , 0.00048994, 0.        ,\n",
       "        0.00048992, 0.        , 0.00040026, 0.        , 0.00039997,\n",
       "        0.00040045, 0.00049039, 0.00040016, 0.        , 0.00048992,\n",
       "        0.00048992, 0.        , 0.00039997, 0.00039997, 0.00039997,\n",
       "        0.00049091, 0.        , 0.00040007, 0.00048986, 0.        ,\n",
       "        0.00039997, 0.00039997, 0.00039997, 0.00039997, 0.00048998]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_l1_ratio': masked_array(data=[0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 0.0,\n",
       "                    0.1, 0.2, 0.30000000000000004, 0.4, 0.5,\n",
       "                    0.6000000000000001, 0.7000000000000001, 0.8, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001, 'l1_ratio': 0.0},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9}],\n",
       " 'split0_test_score': array([ 0.5119    ,  0.51190844,  0.51191684,  0.51192535,  0.51193375,\n",
       "         0.51194212,  0.51195075,  0.51195913,  0.51196749,  0.51198232,\n",
       "         0.51196967,  0.51206681,  0.51216929,  0.51227074,  0.5123718 ,\n",
       "         0.51247251,  0.51257288,  0.51267291,  0.51277261,  0.51287187,\n",
       "         0.51254388,  0.51345026,  0.51438815,  0.51530158,  0.51618566,\n",
       "         0.51703988,  0.51786101,  0.518641  ,  0.51939429,  0.52009623,\n",
       "         0.51002553,  0.51263442,  0.51387264,  0.51282687,  0.51060076,\n",
       "         0.50762503,  0.50470977,  0.501551  ,  0.49719432,  0.49256049,\n",
       "         0.41534593,  0.37279483,  0.32448991,  0.2854945 ,  0.26311092,\n",
       "         0.24945781,  0.2373998 ,  0.22284898,  0.20501203,  0.18274076,\n",
       "         0.14637811,  0.01545765, -0.00216055, -0.00216055, -0.00216055,\n",
       "        -0.00216055, -0.00216055, -0.00216055, -0.00216055, -0.00216055,\n",
       "         0.01789533, -0.00216055, -0.00216055, -0.00216055, -0.00216055,\n",
       "        -0.00216055, -0.00216055, -0.00216055, -0.00216055, -0.00216055]),\n",
       " 'split1_test_score': array([ 0.58550869,  0.58551263,  0.5855166 ,  0.58552057,  0.58552453,\n",
       "         0.58552849,  0.58553244,  0.58553639,  0.58553585,  0.58553922,\n",
       "         0.58559656,  0.58562997,  0.58566302,  0.58569679,  0.58572971,\n",
       "         0.58576228,  0.58579466,  0.58582712,  0.58585918,  0.5858912 ,\n",
       "         0.58632243,  0.58653856,  0.58680428,  0.5870463 ,  0.58726213,\n",
       "         0.5874575 ,  0.58765102,  0.58777054,  0.58788162,  0.58794952,\n",
       "         0.58377008,  0.58352504,  0.58210956,  0.57965492,  0.57649543,\n",
       "         0.57170723,  0.56622119,  0.56040986,  0.55505298,  0.55021209,\n",
       "         0.46937415,  0.41496959,  0.34325834,  0.29296715,  0.25972776,\n",
       "         0.24671572,  0.23388101,  0.21844059,  0.19957456,  0.17609912,\n",
       "         0.15878371,  0.01365207, -0.00294441, -0.00294441, -0.00294441,\n",
       "        -0.00294441, -0.00294441, -0.00294441, -0.00294441, -0.00294441,\n",
       "         0.01859494, -0.00294441, -0.00294441, -0.00294441, -0.00294441,\n",
       "        -0.00294441, -0.00294441, -0.00294441, -0.00294441, -0.00294441]),\n",
       " 'split2_test_score': array([ 0.59762243,  0.59762102,  0.59761886,  0.5976171 ,  0.59761918,\n",
       "         0.59761845,  0.59761772,  0.59761719,  0.59761977,  0.59761946,\n",
       "         0.59751606,  0.59750962,  0.59751395,  0.59751135,  0.59750803,\n",
       "         0.59750021,  0.59748989,  0.59748246,  0.59747241,  0.59746155,\n",
       "         0.59636054,  0.59632495,  0.59635953,  0.5963036 ,  0.59613545,\n",
       "         0.59592785,  0.59568346,  0.59541642,  0.59512431,  0.59477918,\n",
       "         0.57993567,  0.57902429,  0.57463102,  0.5678907 ,  0.5609748 ,\n",
       "         0.55442718,  0.54688675,  0.53850383,  0.52941561,  0.52049968,\n",
       "         0.44050266,  0.38499063,  0.32260876,  0.26921356,  0.24513938,\n",
       "         0.23085081,  0.21759566,  0.20159982,  0.1819855 ,  0.15747814,\n",
       "         0.13619308, -0.00084489, -0.01639387, -0.01639387, -0.01639387,\n",
       "        -0.01639387, -0.01639387, -0.01639387, -0.01639387, -0.01639387,\n",
       "         0.00380712, -0.01639387, -0.01639387, -0.01639387, -0.01639387,\n",
       "        -0.01639387, -0.01639387, -0.01639387, -0.01639387, -0.01639387]),\n",
       " 'split3_test_score': array([ 5.63821610e-01,  5.63813436e-01,  5.63806528e-01,  5.63799528e-01,\n",
       "         5.63792582e-01,  5.63785591e-01,  5.63778508e-01,  5.63771291e-01,\n",
       "         5.63765664e-01,  5.63758564e-01,  5.63625885e-01,  5.63588487e-01,\n",
       "         5.63541000e-01,  5.63501403e-01,  5.63535581e-01,  5.63569226e-01,\n",
       "         5.63602935e-01,  5.63636291e-01,  5.63669353e-01,  5.63702073e-01,\n",
       "         5.63880719e-01,  5.64040591e-01,  5.64256683e-01,  5.64543116e-01,\n",
       "         5.64802535e-01,  5.65037411e-01,  5.65247418e-01,  5.65414620e-01,\n",
       "         5.65573032e-01,  5.65706285e-01,  5.59019801e-01,  5.59433171e-01,\n",
       "         5.57802257e-01,  5.54130237e-01,  5.50904985e-01,  5.48125167e-01,\n",
       "         5.44885318e-01,  5.40951732e-01,  5.35949737e-01,  5.31276785e-01,\n",
       "         4.52572555e-01,  4.13979479e-01,  3.58999803e-01,  3.05983585e-01,\n",
       "         2.76676603e-01,  2.61591677e-01,  2.48826785e-01,  2.33358522e-01,\n",
       "         2.14308240e-01,  1.90396226e-01,  1.59305436e-01,  1.74549340e-02,\n",
       "        -2.82782818e-04, -2.82782818e-04, -2.82782818e-04, -2.82782818e-04,\n",
       "        -2.82782818e-04, -2.82782818e-04, -2.82782818e-04, -2.82782818e-04,\n",
       "         2.11633762e-02, -2.82782818e-04, -2.82782818e-04, -2.82782818e-04,\n",
       "        -2.82782818e-04, -2.82782818e-04, -2.82782818e-04, -2.82782818e-04,\n",
       "        -2.82782818e-04, -2.82782818e-04]),\n",
       " 'split4_test_score': array([ 0.45563464,  0.45564272,  0.4556508 ,  0.45566026,  0.45566891,\n",
       "         0.45567756,  0.4556862 ,  0.4556945 ,  0.45570308,  0.45571161,\n",
       "         0.45582032,  0.45590201,  0.45598703,  0.45607181,  0.45615648,\n",
       "         0.45624107,  0.4563129 ,  0.45639154,  0.45647033,  0.45654788,\n",
       "         0.45749871,  0.45822739,  0.45897944,  0.45971209,  0.46038329,\n",
       "         0.46103252,  0.46166454,  0.46227689,  0.46287133,  0.46343836,\n",
       "         0.46298096,  0.46701263,  0.46955539,  0.47123371,  0.47202888,\n",
       "         0.47206051,  0.47060462,  0.46692423,  0.46297795,  0.45861444,\n",
       "         0.38669643,  0.3578573 ,  0.30593748,  0.26151408,  0.23746868,\n",
       "         0.22508848,  0.21451789,  0.20167574,  0.18581701,  0.16585443,\n",
       "         0.13597051,  0.01368845, -0.00221793, -0.00221793, -0.00221793,\n",
       "        -0.00221793, -0.00221793, -0.00221793, -0.00221793, -0.00221793,\n",
       "         0.01640526, -0.00221793, -0.00221793, -0.00221793, -0.00221793,\n",
       "        -0.00221793, -0.00221793, -0.00221793, -0.00221793, -0.00221793]),\n",
       " 'mean_test_score': array([ 0.54289747,  0.54289965,  0.54290192,  0.54290456,  0.54290779,\n",
       "         0.54291044,  0.54291312,  0.5429157 ,  0.54291837,  0.54292224,\n",
       "         0.5429057 ,  0.54293938,  0.54297486,  0.54301042,  0.54306032,\n",
       "         0.54310906,  0.54315465,  0.54320206,  0.54324878,  0.54329492,\n",
       "         0.54332126,  0.54371635,  0.54415762,  0.54458134,  0.54495381,\n",
       "         0.54529903,  0.54562149,  0.54590389,  0.54616892,  0.54639392,\n",
       "         0.53914641,  0.54032591,  0.53959417,  0.53714729,  0.53420097,\n",
       "         0.53078902,  0.52666153,  0.52166813,  0.51611812,  0.5106327 ,\n",
       "         0.43289835,  0.38891837,  0.33105886,  0.28303457,  0.25642467,\n",
       "         0.2427409 ,  0.23044423,  0.21558473,  0.19733947,  0.17451374,\n",
       "         0.14732617,  0.01188164, -0.00479991, -0.00479991, -0.00479991,\n",
       "        -0.00479991, -0.00479991, -0.00479991, -0.00479991, -0.00479991,\n",
       "         0.0155732 , -0.00479991, -0.00479991, -0.00479991, -0.00479991,\n",
       "        -0.00479991, -0.00479991, -0.00479991, -0.00479991, -0.00479991]),\n",
       " 'std_test_score': array([0.05258137, 0.05257739, 0.05257336, 0.05256894, 0.0525656 ,\n",
       "        0.05256168, 0.05255772, 0.05255393, 0.0525501 , 0.05254544,\n",
       "        0.05248815, 0.05245074, 0.05241302, 0.05237482, 0.0523422 ,\n",
       "        0.05230862, 0.05227878, 0.05224732, 0.05221522, 0.05218339,\n",
       "        0.0517643 , 0.05145655, 0.05116501, 0.05086655, 0.05056344,\n",
       "        0.05025861, 0.04995452, 0.04964215, 0.04933248, 0.04901869,\n",
       "        0.04625838, 0.04443078, 0.04226985, 0.03994136, 0.03796583,\n",
       "        0.03610876, 0.03443948, 0.03334011, 0.03245929, 0.03200802,\n",
       "        0.0290451 , 0.0225695 , 0.0183039 , 0.01603444, 0.01380177,\n",
       "        0.01318522, 0.01278158, 0.01237635, 0.01200262, 0.01172728,\n",
       "        0.01028177, 0.0065148 , 0.00586345, 0.00586345, 0.00586345,\n",
       "        0.00586345, 0.00586345, 0.00586345, 0.00586345, 0.00586345,\n",
       "        0.00608122, 0.00586345, 0.00586345, 0.00586345, 0.00586345,\n",
       "        0.00586345, 0.00586345, 0.00586345, 0.00586345, 0.00586345]),\n",
       " 'rank_test_score': array([30, 29, 28, 27, 25, 24, 23, 22, 21, 20, 26, 19, 18, 17, 16, 15, 14,\n",
       "        13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1, 33, 31, 32, 34,\n",
       "        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "        53, 54, 54, 54, 54, 54, 54, 54, 54, 52, 54, 54, 54, 54, 54, 54, 54,\n",
       "        54, 54])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Résultats complets du GridSearch\n",
    "elastic_net_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea39e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'l1_ratio': 0.9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage les hyperparamètres optimaux\n",
    "print(\"Les meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net :\")\n",
    "elastic_net_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3c9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs paramètres\n",
    "y_el_net_pred=elastic_net_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aa001b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.43\n",
      "R2 test : 0.54\n",
      "R2 train : 0.5463939154343668\n",
      "Temps d'execution :0.011965249606541224 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Elastic Net sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_el_net_pred)) ))\n",
    "print(\"R2 test : {:.2f}\".format(elastic_net_grid.score(X_test,y_test) ))\n",
    "print(\"R2 train : \" + str(elastic_net_grid.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (elastic_net_grid.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df861d1",
   "metadata": {},
   "source": [
    "# 1.4 Modèle non linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfdc0c8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89136233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ................min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=300; total time=   0.9s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ...............min_samples_leaf=1, n_estimators=500; total time=   1.6s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.7s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.7s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=300; total time=   0.7s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.2s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.2s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.1s\n",
      "[CV] END ...............min_samples_leaf=3, n_estimators=500; total time=   1.1s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ................min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...............min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..............min_samples_leaf=10, n_estimators=500; total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'min_samples_leaf': [1, 3, 5, 10],\n",
       "                         'n_estimators': [10, 50, 100, 300, 500]},\n",
       "             scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\n",
    "    'n_estimators' : [10,50,100,300,500], #nombre d'arbres de décision\n",
    "    'min_samples_leaf' : [1,3,5,10], #nombre de feuilles minimales dans un noeud\n",
    "    #'max_features': ['auto', 'sqrt'] #nombre de features observées pour chaque arbre\n",
    "}\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "\n",
    "random_forest_grid = model_selection.GridSearchCV(RandomForestRegressor(),\n",
    "                               param_grid = parameters,\n",
    "                               scoring=score,\n",
    "                              verbose=2,\n",
    "                               cv=5)\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "random_forest_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9869c969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs hyperparamètres pour le modèle non linéaire Random Forest \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 5, 'n_estimators': 300}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les hyperparamètres optimaux\n",
    "print(\"Les meilleurs hyperparamètres pour le modèle non linéaire Random Forest \")\n",
    "random_forest_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58030930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs parametres\n",
    "y_rand_for_pred = random_forest_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9261152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.52\n",
      "R2 test : 0.49\n",
      "R2 train : 0.48946725398639546\n",
      "Temps d'execution :0.46099947452545165 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Random Forest sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_rand_for_pred)) ))\n",
    "print(\"R2 test : {:.2f}\".format(random_forest_grid.score(X_test,y_test) ))\n",
    "print(\"R2 train : \"+ str(random_forest_grid.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (random_forest_grid.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "521c6232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46099947452545165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Temps d'exécution\n",
    "random_forest_grid.cv_results_['mean_fit_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5162ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.6 ms ± 137 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit random_forest_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458425ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32b86dd5",
   "metadata": {},
   "source": [
    "# <a name=\"C2\">2. Deuxième itération </a>\n",
    "## 2.1 Import et préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598a497",
   "metadata": {},
   "source": [
    "### 2.1 Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc1c9cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>log_TotalGHGEmissions</th>\n",
       "      <th>log_SiteEnergyUse(kBtu)</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Non-Refrigerated Warehouse</th>\n",
       "      <th>x0_Other - Recreation</th>\n",
       "      <th>x0_Supermarket/Grocery Store</th>\n",
       "      <th>x0_Worship Facility</th>\n",
       "      <th>x0_Restaurant</th>\n",
       "      <th>Office</th>\n",
       "      <th>Other</th>\n",
       "      <th>Retail Store</th>\n",
       "      <th>infrequent</th>\n",
       "      <th>Parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.971429</td>\n",
       "      <td>22.784838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>8.213639</td>\n",
       "      <td>22.999884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>11.029480</td>\n",
       "      <td>26.113208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.167067</td>\n",
       "      <td>22.695954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>8.983022</td>\n",
       "      <td>23.756602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.414812</td>\n",
       "      <td>19.830099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.051807</td>\n",
       "      <td>19.857989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.810829</td>\n",
       "      <td>22.459114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423653</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.530445</td>\n",
       "      <td>19.456579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.401562</td>\n",
       "      <td>20.136833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  log_TotalGHGEmissions  log_SiteEnergyUse(kBtu)  \\\n",
       "0                   0.000000               7.971429                22.784838   \n",
       "1                  13.878913               8.213639                22.999884   \n",
       "2                  17.585777              11.029480                26.113208   \n",
       "3                   0.000000               8.167067                22.695954   \n",
       "4                  15.920004               8.983022                23.756602   \n",
       "...                      ...                    ...                      ...   \n",
       "1542                0.000000               4.414812                19.830099   \n",
       "1543                0.000000               5.051807                19.857989   \n",
       "1544                0.000000               7.810829                22.459114   \n",
       "1545                0.000000               4.530445                19.456579   \n",
       "1546                0.000000               5.401562                20.136833   \n",
       "\n",
       "      x0_Campus  x0_NonResidential  x0_Nonresidential COS  \\\n",
       "0           0.0                1.0                    0.0   \n",
       "1           0.0                1.0                    0.0   \n",
       "2           0.0                1.0                    0.0   \n",
       "3           0.0                1.0                    0.0   \n",
       "4           0.0                1.0                    0.0   \n",
       "...         ...                ...                    ...   \n",
       "1542        0.0                0.0                    1.0   \n",
       "1543        0.0                0.0                    1.0   \n",
       "1544        0.0                0.0                    1.0   \n",
       "1545        0.0                0.0                    1.0   \n",
       "1546        0.0                0.0                    1.0   \n",
       "\n",
       "      x0_Nonresidential WA  ...  x0_Non-Refrigerated Warehouse  \\\n",
       "0                      0.0  ...                            0.0   \n",
       "1                      0.0  ...                            0.0   \n",
       "2                      0.0  ...                            0.0   \n",
       "3                      0.0  ...                            0.0   \n",
       "4                      0.0  ...                            0.0   \n",
       "...                    ...  ...                            ...   \n",
       "1542                   0.0  ...                            0.0   \n",
       "1543                   0.0  ...                            0.0   \n",
       "1544                   0.0  ...                            0.0   \n",
       "1545                   0.0  ...                            0.0   \n",
       "1546                   0.0  ...                            0.0   \n",
       "\n",
       "      x0_Other - Recreation  x0_Supermarket/Grocery Store  \\\n",
       "0                  0.000000                           0.0   \n",
       "1                  0.000000                           0.0   \n",
       "2                  0.000000                           0.0   \n",
       "3                  0.000000                           0.0   \n",
       "4                  0.000000                           0.0   \n",
       "...                     ...                           ...   \n",
       "1542               1.000000                           0.0   \n",
       "1543               1.000000                           0.0   \n",
       "1544               0.576347                           0.0   \n",
       "1545               0.485868                           0.0   \n",
       "1546               0.475919                           0.0   \n",
       "\n",
       "      x0_Worship Facility  x0_Restaurant  Office  Other  Retail Store  \\\n",
       "0                     0.0       0.000000     0.0    0.0           0.0   \n",
       "1                     0.0       0.044629     0.0    0.0           0.0   \n",
       "2                     0.0       0.000000     0.0    0.0           0.0   \n",
       "3                     0.0       0.000000     0.0    0.0           0.0   \n",
       "4                     0.0       0.000000     0.0    0.0           0.0   \n",
       "...                   ...            ...     ...    ...           ...   \n",
       "1542                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1543                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1544                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1545                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1546                  0.0       0.000000     0.0    0.0           0.0   \n",
       "\n",
       "      infrequent   Parking  \n",
       "0       0.000000  0.000000  \n",
       "1       0.000000  0.145453  \n",
       "2       0.000000  0.000000  \n",
       "3       0.000000  0.000000  \n",
       "4       0.000000  0.355224  \n",
       "...          ...       ...  \n",
       "1542    0.000000  0.000000  \n",
       "1543    0.000000  0.000000  \n",
       "1544    0.423653  0.000000  \n",
       "1545    0.514132  0.000000  \n",
       "1546    0.524081  0.000000  \n",
       "\n",
       "[1547 rows x 71 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lecture et affichage du fichier '2016_Building_Energy_Benchmarking_clean_model_2.csv'\n",
    "data_2=pd.read_csv('2016_Building_Energy_Benchmarking_clean_model_2.csv')\n",
    "data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad0c19",
   "metadata": {},
   "source": [
    "### 2.1 Préparation des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "914e3008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Séparation Features Target\n",
    "#Target y : TotalGHGEmissions\n",
    "y_2=data_2['log_TotalGHGEmissions'].values\n",
    "#y=model_data['SiteEnergyUse(kBtu)'].values\n",
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "658ee141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>x0_SPS-District K-12</th>\n",
       "      <th>x1_Distribution Center</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Non-Refrigerated Warehouse</th>\n",
       "      <th>x0_Other - Recreation</th>\n",
       "      <th>x0_Supermarket/Grocery Store</th>\n",
       "      <th>x0_Worship Facility</th>\n",
       "      <th>x0_Restaurant</th>\n",
       "      <th>Office</th>\n",
       "      <th>Other</th>\n",
       "      <th>Retail Store</th>\n",
       "      <th>infrequent</th>\n",
       "      <th>Parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423653</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  x0_Campus  x0_NonResidential  \\\n",
       "0                   0.000000        0.0                1.0   \n",
       "1                  13.878913        0.0                1.0   \n",
       "2                  17.585777        0.0                1.0   \n",
       "3                   0.000000        0.0                1.0   \n",
       "4                  15.920004        0.0                1.0   \n",
       "...                      ...        ...                ...   \n",
       "1542                0.000000        0.0                0.0   \n",
       "1543                0.000000        0.0                0.0   \n",
       "1544                0.000000        0.0                0.0   \n",
       "1545                0.000000        0.0                0.0   \n",
       "1546                0.000000        0.0                0.0   \n",
       "\n",
       "      x0_Nonresidential COS  x0_Nonresidential WA  x0_SPS-District K-12  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "1542                    1.0                   0.0                   0.0   \n",
       "1543                    1.0                   0.0                   0.0   \n",
       "1544                    1.0                   0.0                   0.0   \n",
       "1545                    1.0                   0.0                   0.0   \n",
       "1546                    1.0                   0.0                   0.0   \n",
       "\n",
       "      x1_Distribution Center  ...  x0_Non-Refrigerated Warehouse  \\\n",
       "0                        0.0  ...                            0.0   \n",
       "1                        0.0  ...                            0.0   \n",
       "2                        0.0  ...                            0.0   \n",
       "3                        0.0  ...                            0.0   \n",
       "4                        0.0  ...                            0.0   \n",
       "...                      ...  ...                            ...   \n",
       "1542                     0.0  ...                            0.0   \n",
       "1543                     0.0  ...                            0.0   \n",
       "1544                     0.0  ...                            0.0   \n",
       "1545                     0.0  ...                            0.0   \n",
       "1546                     0.0  ...                            0.0   \n",
       "\n",
       "      x0_Other - Recreation  x0_Supermarket/Grocery Store  \\\n",
       "0                  0.000000                           0.0   \n",
       "1                  0.000000                           0.0   \n",
       "2                  0.000000                           0.0   \n",
       "3                  0.000000                           0.0   \n",
       "4                  0.000000                           0.0   \n",
       "...                     ...                           ...   \n",
       "1542               1.000000                           0.0   \n",
       "1543               1.000000                           0.0   \n",
       "1544               0.576347                           0.0   \n",
       "1545               0.485868                           0.0   \n",
       "1546               0.475919                           0.0   \n",
       "\n",
       "      x0_Worship Facility  x0_Restaurant  Office  Other  Retail Store  \\\n",
       "0                     0.0       0.000000     0.0    0.0           0.0   \n",
       "1                     0.0       0.044629     0.0    0.0           0.0   \n",
       "2                     0.0       0.000000     0.0    0.0           0.0   \n",
       "3                     0.0       0.000000     0.0    0.0           0.0   \n",
       "4                     0.0       0.000000     0.0    0.0           0.0   \n",
       "...                   ...            ...     ...    ...           ...   \n",
       "1542                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1543                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1544                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1545                  0.0       0.000000     0.0    0.0           0.0   \n",
       "1546                  0.0       0.000000     0.0    0.0           0.0   \n",
       "\n",
       "      infrequent   Parking  \n",
       "0       0.000000  0.000000  \n",
       "1       0.000000  0.145453  \n",
       "2       0.000000  0.000000  \n",
       "3       0.000000  0.000000  \n",
       "4       0.000000  0.355224  \n",
       "...          ...       ...  \n",
       "1542    0.000000  0.000000  \n",
       "1543    0.000000  0.000000  \n",
       "1544    0.423653  0.000000  \n",
       "1545    0.514132  0.000000  \n",
       "1546    0.524081  0.000000  \n",
       "\n",
       "[1547 rows x 69 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe des Features, on retire les colonnes targets\n",
    "model_2_data=data_2.copy()\n",
    "targets_2=['log_SiteEnergyUse(kBtu)','log_TotalGHGEmissions']\n",
    "model_2_data.drop(targets_2,axis=1, inplace=True)\n",
    "model_2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e515d048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 69)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2=model_2_data.values\n",
    "X_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08f4aa",
   "metadata": {},
   "source": [
    "#### Standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b921852f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04246324,  1.80319003,  0.35194475, ..., -0.31596173,\n",
       "        -0.58677238, -0.43189048],\n",
       "       [-0.04246324,  1.68388254,  0.51427078, ..., -0.31596173,\n",
       "        -0.58677238,  0.8982949 ],\n",
       "       [-0.04246324,  3.55118577,  2.79849165, ..., -0.31596173,\n",
       "        -0.58677238, -0.43189048],\n",
       "       ...,\n",
       "       [-0.04246324, -0.9868208 , -1.60606654, ..., -0.31596173,\n",
       "         0.56912102, -0.43189048],\n",
       "       [-0.04246324, -0.9868208 , -1.53486067, ..., -0.31596173,\n",
       "         0.81598478, -0.43189048],\n",
       "       [-0.04246324, -0.9868208 , -1.26936336, ..., -0.31596173,\n",
       "         0.8431285 , -0.43189048]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardisation des données avec StandardScaler()\n",
    "std_scale = preprocessing.StandardScaler()\n",
    "X_2 = std_scale.fit_transform(X_2)\n",
    "X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837c598",
   "metadata": {},
   "source": [
    "#### Split du jeu de données en données d'entraînement et données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e72540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement X_train : (1237, 69)\n",
      "Taille du jeu de test X_test: (310, 69)\n",
      "Taille de y_train : (1237,)\n",
      "Taille de y_test : (310,)\n"
     ]
    }
   ],
   "source": [
    "# Split du jeu de données en données d'entraînement et données de test\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = model_selection.train_test_split(X_2, y_2, test_size=0.2, random_state=42) # 20% des données dans le jeu de test\n",
    "#X_train_2, X_test_2, y_train_2, y_test_2 = model_selection.train_test_split(X_2, y_2, test_size=0.2, shuffle=False) # 30% des données dans le jeu de test\n",
    "print(\"Taille du jeu d'entraînement X_train : \"+ str(X_train_2.shape))\n",
    "print(\"Taille du jeu de test X_test: \"+ str(X_test_2.shape))\n",
    "print(\"Taille de y_train : \"+ str(y_train_2.shape))\n",
    "print(\"Taille de y_test : \"+ str(y_test_2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af7b67",
   "metadata": {},
   "source": [
    "## 2.2 Approche Naïve : DummyRegrossor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2f4ec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 2.12\n",
      "R2 : -0.00\n"
     ]
    }
   ],
   "source": [
    "#Strategie : moyenne\n",
    "dum_reg_2 = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entraînement\n",
    "dum_reg_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_dum_2 = dum_reg_2.predict(X_test_2)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_2, y_pred_dum_2)) ))\n",
    "print(\"R2 : {:.2f}\".format(dum_reg_2.score(X_test_2,y_test_2) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c976ae",
   "metadata": {},
   "source": [
    "## 2.3 ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdf39ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.350e+02, tolerance: 4.354e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.455e+02, tolerance: 4.293e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.418e+02, tolerance: 4.310e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.516e+02, tolerance: 4.308e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.711e+02, tolerance: 4.286e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.905e+02, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.979e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.257e+02, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.839e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.282e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.015e+01, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.851e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.719e+02, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.225e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.149e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.854e+01, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.909e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.596e+02, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.668e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.242e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.861e+00, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.141e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.757e+02, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.160e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+00, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.479e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+02, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.696e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.905e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+00, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+02, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.270e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.402e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+00, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+02, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.877e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+00, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.440e+01, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.516e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+00, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e+02, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.072e+01, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.182e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+02, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.367e+02, tolerance: 4.354e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.469e+02, tolerance: 4.293e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.436e+02, tolerance: 4.310e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.533e+02, tolerance: 4.308e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.724e+02, tolerance: 4.286e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+01, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+01, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+01, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+02, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e+01, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.891e+00, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+00, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.378e-01, tolerance: 4.310e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+01, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+00, tolerance: 4.286e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+00, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+00, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.127e+00, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.282e-01, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+00, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e+00, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+00, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+00, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.370e-01, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+00, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.885e+00, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.811e-01, tolerance: 4.354e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.912e+00, tolerance: 4.293e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.845e+00, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.845e+00, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+00, tolerance: 4.308e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.514e+02, tolerance: 4.354e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.592e+02, tolerance: 4.293e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.583e+02, tolerance: 4.310e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.667e+02, tolerance: 4.308e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.844e+02, tolerance: 4.286e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.545e+02, tolerance: 4.354e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.478e+02, tolerance: 4.293e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.582e+02, tolerance: 4.310e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.630e+02, tolerance: 4.308e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.781e+02, tolerance: 4.286e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+03, tolerance: 4.354e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+03, tolerance: 4.293e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+03, tolerance: 4.310e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+03, tolerance: 4.308e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+03, tolerance: 4.286e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+03, tolerance: 4.354e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.909e+03, tolerance: 4.293e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.930e+03, tolerance: 4.310e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.927e+03, tolerance: 4.308e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.924e+03, tolerance: 4.286e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+03, tolerance: 4.354e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+03, tolerance: 4.293e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+03, tolerance: 4.310e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+03, tolerance: 4.308e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e+03, tolerance: 4.286e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'l1_ratio': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef de régularisation. Si égale à 0, équivaut à régresison linéaire simple\n",
    "              \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}#L1 ratio , si égal à 1 équivaut à un Lasso, si égal 0 à un Ridge\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "elastic_net_grid_2 = model_selection.GridSearchCV(estimator = linear_model.ElasticNet(),  # ElasticNet regression\n",
    "                      param_grid = parameters,  # hyperparamètres à tester\n",
    "                    scoring = score,  # score à optimiser R2\n",
    "                      cv=5, # nombre de folds de validation croisée\n",
    "                      verbose=0\n",
    "                     )\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "elastic_net_grid_2.fit(X_train_2, y_train_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45a5bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les Meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'l1_ratio': 0.9}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les hyperparamètres optimaux\n",
    "print(\"Les Meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net:\")\n",
    "elastic_net_grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fd074db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs parametres\n",
    "y_el_net_pred_2=elastic_net_grid_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "622cc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.44\n",
      "R2 test : 0.54\n",
      "R2 train : 0.5517360254824817\n",
      "Temps d'execution 0.014953763144356863 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Elastic Net sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_2, y_el_net_pred_2)) ))\n",
    "print(\"R2 test : {:.2f}\".format(elastic_net_grid_2.score(X_test_2,y_test_2) ))\n",
    "print(\"R2 train : \" + str(elastic_net_grid_2.best_score_))\n",
    "print(\"Temps d'execution \"+ str(elastic_net_grid_2.cv_results_['mean_fit_time'].mean())+\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402297ad",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10f755b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients des features dans le modèle\n",
    "coefficients_el_net = abs(elastic_net_grid_2.best_estimator_.coef_)\n",
    "liste_coefs_el_net = pd.concat((pd.DataFrame(model_2_data.columns, columns = ['Features']), \n",
    "                      pd.DataFrame(coefficients_el_net, columns = ['Coefficient'])), axis = 1).sort_values(by='Coefficient', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2e02e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Elastic Net - Emission - Importance des 15 premières Features')\n",
    "sns.barplot(y = liste_coefs_el_net['Features'].head(15),\n",
    "            x = liste_coefs_el_net['Coefficient'].head(15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb9532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9623cee6",
   "metadata": {},
   "source": [
    "## 2.4 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c06c3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=10;, score=0.400 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=10;, score=0.463 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=10;, score=0.512 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=10;, score=0.515 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=10;, score=0.544 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=50;, score=0.455 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=50;, score=0.495 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=50;, score=0.505 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=50;, score=0.503 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=50;, score=0.573 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=100;, score=0.421 total time=   0.3s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=100;, score=0.501 total time=   0.3s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=100;, score=0.506 total time=   0.3s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=100;, score=0.499 total time=   0.3s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=100;, score=0.574 total time=   0.3s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=300;, score=0.452 total time=   1.2s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=300;, score=0.504 total time=   1.2s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=300;, score=0.514 total time=   1.2s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=300;, score=0.512 total time=   1.2s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=300;, score=0.574 total time=   1.2s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=500;, score=0.445 total time=   2.0s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=500;, score=0.497 total time=   2.0s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=500;, score=0.508 total time=   2.0s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=500;, score=0.508 total time=   2.0s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=500;, score=0.578 total time=   2.0s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=10;, score=0.428 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=10;, score=0.501 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=10;, score=0.482 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=10;, score=0.502 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=10;, score=0.531 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=50;, score=0.460 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=50;, score=0.504 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=50;, score=0.511 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=50;, score=0.530 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=50;, score=0.574 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=100;, score=0.455 total time=   0.2s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=100;, score=0.501 total time=   0.2s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=100;, score=0.507 total time=   0.2s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=100;, score=0.532 total time=   0.2s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=100;, score=0.564 total time=   0.2s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=300;, score=0.457 total time=   0.8s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=300;, score=0.503 total time=   0.9s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=300;, score=0.503 total time=   0.8s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=300;, score=0.534 total time=   0.8s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=300;, score=0.566 total time=   0.8s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=500;, score=0.460 total time=   1.5s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=500;, score=0.508 total time=   1.5s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=500;, score=0.513 total time=   1.5s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=500;, score=0.534 total time=   1.5s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=500;, score=0.568 total time=   1.5s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=10;, score=0.454 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=10;, score=0.478 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=10;, score=0.492 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=10;, score=0.539 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=10;, score=0.512 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=50;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=50;, score=0.515 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=50;, score=0.500 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=50;, score=0.535 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=50;, score=0.565 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=100;, score=0.449 total time=   0.2s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=100;, score=0.505 total time=   0.2s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=100;, score=0.501 total time=   0.2s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=100;, score=0.539 total time=   0.2s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=100;, score=0.551 total time=   0.2s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=300;, score=0.453 total time=   0.7s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=300;, score=0.509 total time=   0.7s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=300;, score=0.500 total time=   0.7s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=300;, score=0.536 total time=   0.7s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=300;, score=0.557 total time=   0.7s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=500;, score=0.453 total time=   1.3s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=500;, score=0.506 total time=   1.3s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=500;, score=0.501 total time=   1.3s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=500;, score=0.539 total time=   1.3s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=500;, score=0.556 total time=   1.3s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=10;, score=0.404 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=10;, score=0.450 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=10;, score=0.434 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=10;, score=0.499 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=10;, score=0.517 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=50;, score=0.417 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=50;, score=0.479 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=50;, score=0.465 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=50;, score=0.513 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=50;, score=0.520 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=100;, score=0.420 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=100;, score=0.479 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=100;, score=0.461 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=100;, score=0.517 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=100;, score=0.532 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=300;, score=0.424 total time=   0.6s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=300;, score=0.480 total time=   0.6s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=300;, score=0.466 total time=   0.6s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=300;, score=0.514 total time=   0.6s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=300;, score=0.524 total time=   0.6s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=500;, score=0.426 total time=   1.0s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=500;, score=0.475 total time=   1.0s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=500;, score=0.468 total time=   1.0s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=500;, score=0.514 total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END min_samples_leaf=10, n_estimators=500;, score=0.528 total time=   1.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'min_samples_leaf': [1, 3, 5, 10],\n",
       "                         'n_estimators': [10, 50, 100, 300, 500]},\n",
       "             scoring='r2', verbose=5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\n",
    "    'n_estimators' : [10,50,100,300,500], #nombre d'arbres de décision\n",
    "    'min_samples_leaf' : [1,3,5,10], #nombre de feuilles minimales dans un noeud\n",
    "}\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "\n",
    "random_forest_grid_2 = model_selection.GridSearchCV(RandomForestRegressor(),\n",
    "                               param_grid = parameters,\n",
    "                               scoring=score,\n",
    "                              verbose=5,\n",
    "                               cv=5)\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "random_forest_grid_2.fit(X_train_2, y_train_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7638818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs hyperparamètres pour le modèle non linéaire Random Forest \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 3, 'n_estimators': 500}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les hyperparamètres optimaux\n",
    "print(\"Les meilleurs hyperparamètres pour le modèle non linéaire Random Forest \")\n",
    "random_forest_grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "609398b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs parametres\n",
    "y_rand_for_pred_2 = random_forest_grid_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f946926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.50\n",
      "R2 : 0.50\n",
      "R2 : 0.5167752302340695\n",
      "Temps d'execution :0.5821694588661194 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Random Forest sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_2, y_rand_for_pred_2)) ))\n",
    "print(\"R2 : {:.2f}\".format(random_forest_grid_2.score(X_test_2,y_test_2) ))\n",
    "print(\"R2 : \"+ str(random_forest_grid_2.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (random_forest_grid_2.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05415e70",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2afd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients des features dans le modèle\n",
    "coefficients_rand_for = abs(random_forest_grid_2.best_estimator_.feature_importances_)\n",
    "liste_coefs_rand_for = pd.concat((pd.DataFrame(model_2_data.columns, columns = ['Features']), \n",
    "                      pd.DataFrame(coefficients_rand_for, columns = ['Coefficient'])), axis = 1).sort_values(by='Coefficient', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45efefe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('RandomForest - Emission - Importance des 15 premières Features')\n",
    "sns.barplot(y = liste_coefs_rand_for['Features'].head(15),\n",
    "            x = liste_coefs_rand_for['Coefficient'].head(15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fc439",
   "metadata": {},
   "source": [
    "# <a name=\"C3\">3. Troisième itération : intérêt de ENERGY STAR Score </a>\n",
    "## 3.1 Import et préparation des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7152f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>log_TotalGHGEmissions</th>\n",
       "      <th>log_SiteEnergyUse(kBtu)</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Parking</th>\n",
       "      <th>x0_Retail Store_second</th>\n",
       "      <th>x0_infrequent_sklearn_second</th>\n",
       "      <th>x0_NA_third</th>\n",
       "      <th>x0_Office_third</th>\n",
       "      <th>x0_Other_third</th>\n",
       "      <th>x0_Parking_third</th>\n",
       "      <th>x0_Restaurant</th>\n",
       "      <th>x0_Retail Store_third</th>\n",
       "      <th>x0_infrequent_sklearn_third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.971429</td>\n",
       "      <td>22.784838</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>8.213639</td>\n",
       "      <td>22.999884</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>11.029480</td>\n",
       "      <td>26.113208</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.167067</td>\n",
       "      <td>22.695954</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>8.983022</td>\n",
       "      <td>23.756602</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.807355</td>\n",
       "      <td>19.033751</td>\n",
       "      <td>17.592661</td>\n",
       "      <td>7.943453</td>\n",
       "      <td>23.658296</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>16.952468</td>\n",
       "      <td>15.342214</td>\n",
       "      <td>7.044613</td>\n",
       "      <td>22.526690</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.668608</td>\n",
       "      <td>12.044053</td>\n",
       "      <td>7.310158</td>\n",
       "      <td>21.781911</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>14.609121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.085340</td>\n",
       "      <td>22.075828</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.457669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.356144</td>\n",
       "      <td>20.338621</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                      1.0            3.700440             16.432330   \n",
       "1                      1.0            3.584963             16.660205   \n",
       "2                      1.0            5.392317             19.866819   \n",
       "3                      1.0            3.459432             15.904094   \n",
       "4                      1.0            4.247928             17.421777   \n",
       "..                     ...                 ...                   ...   \n",
       "991                    1.0            3.807355             19.033751   \n",
       "992                    1.0            2.321928             16.952468   \n",
       "993                    1.0            1.000000             15.668608   \n",
       "994                    1.0            1.584963             14.609121   \n",
       "995                    1.0            2.000000             15.457669   \n",
       "\n",
       "     log_PropertyGFAParking  log_TotalGHGEmissions  log_SiteEnergyUse(kBtu)  \\\n",
       "0                  0.000000               7.971429                22.784838   \n",
       "1                 13.878913               8.213639                22.999884   \n",
       "2                 17.585777              11.029480                26.113208   \n",
       "3                  0.000000               8.167067                22.695954   \n",
       "4                 15.920004               8.983022                23.756602   \n",
       "..                      ...                    ...                      ...   \n",
       "991               17.592661               7.943453                23.658296   \n",
       "992               15.342214               7.044613                22.526690   \n",
       "993               12.044053               7.310158                21.781911   \n",
       "994                0.000000               7.085340                22.075828   \n",
       "995                0.000000               3.356144                20.338621   \n",
       "\n",
       "     ENERGYSTARScore  x0_Campus  x0_NonResidential  x0_Nonresidential COS  \\\n",
       "0               60.0        0.0                1.0                    0.0   \n",
       "1               61.0        0.0                1.0                    0.0   \n",
       "2               43.0        0.0                1.0                    0.0   \n",
       "3               56.0        0.0                1.0                    0.0   \n",
       "4               75.0        0.0                1.0                    0.0   \n",
       "..               ...        ...                ...                    ...   \n",
       "991             98.0        0.0                0.0                    1.0   \n",
       "992             72.0        0.0                1.0                    0.0   \n",
       "993             37.0        0.0                1.0                    0.0   \n",
       "994              9.0        0.0                1.0                    0.0   \n",
       "995             77.0        0.0                1.0                    0.0   \n",
       "\n",
       "     ...  x0_Parking  x0_Retail Store_second  x0_infrequent_sklearn_second  \\\n",
       "0    ...    0.000000                     0.0                           0.0   \n",
       "1    ...    0.145453                     0.0                           0.0   \n",
       "2    ...    0.000000                     0.0                           0.0   \n",
       "3    ...    0.000000                     0.0                           0.0   \n",
       "4    ...    0.355224                     0.0                           0.0   \n",
       "..   ...         ...                     ...                           ...   \n",
       "991  ...    0.366710                     0.0                           0.0   \n",
       "992  ...    0.320280                     0.0                           0.0   \n",
       "993  ...    0.000000                     0.0                           0.0   \n",
       "994  ...    0.000000                     0.0                           0.0   \n",
       "995  ...    0.000000                     0.0                           0.0   \n",
       "\n",
       "     x0_NA_third  x0_Office_third  x0_Other_third  x0_Parking_third  \\\n",
       "0            0.0              0.0             0.0               0.0   \n",
       "1            0.0              0.0             0.0               0.0   \n",
       "2            0.0              0.0             0.0               0.0   \n",
       "3            0.0              0.0             0.0               0.0   \n",
       "4            0.0              0.0             0.0               0.0   \n",
       "..           ...              ...             ...               ...   \n",
       "991          0.0              0.0             0.0               0.0   \n",
       "992          0.0              0.0             0.0               0.0   \n",
       "993          0.0              0.0             0.0               0.0   \n",
       "994          0.0              0.0             0.0               0.0   \n",
       "995          0.0              0.0             0.0               0.0   \n",
       "\n",
       "     x0_Restaurant  x0_Retail Store_third  x0_infrequent_sklearn_third  \n",
       "0         0.000000               0.000000                          0.0  \n",
       "1         0.044629               0.000000                          0.0  \n",
       "2         0.000000               0.000000                          0.0  \n",
       "3         0.000000               0.000000                          0.0  \n",
       "4         0.000000               0.000000                          0.0  \n",
       "..             ...                    ...                          ...  \n",
       "991       0.000000               0.011451                          0.0  \n",
       "992       0.000000               0.000000                          0.0  \n",
       "993       0.000000               0.000000                          0.0  \n",
       "994       0.000000               0.000000                          0.0  \n",
       "995       0.000000               0.000000                          0.0  \n",
       "\n",
       "[996 rows x 83 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lecture et affichage du fichier '2016_Building_Energy_Benchmarking_clean_model_1.csv'\n",
    "data_3=pd.read_csv('2016_Building_Energy_Benchmarking_clean_model_3.csv')\n",
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb565eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target y : TotalGHGEmissions\n",
    "y_3=data['log_TotalGHGEmissions'].values\n",
    "y_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8afe49ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_NumberofBuildings</th>\n",
       "      <th>log_NumberofFloors</th>\n",
       "      <th>log_PropertyGFATotal</th>\n",
       "      <th>log_PropertyGFAParking</th>\n",
       "      <th>x0_Campus</th>\n",
       "      <th>x0_NonResidential</th>\n",
       "      <th>x0_Nonresidential COS</th>\n",
       "      <th>x0_Nonresidential WA</th>\n",
       "      <th>x0_SPS-District K-12</th>\n",
       "      <th>x1_Distribution Center</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_1920's</th>\n",
       "      <th>x3_1930's</th>\n",
       "      <th>x3_1940's</th>\n",
       "      <th>x3_1950's</th>\n",
       "      <th>x3_1960's</th>\n",
       "      <th>x3_1970's</th>\n",
       "      <th>x3_1980's</th>\n",
       "      <th>x3_1990's</th>\n",
       "      <th>x3_2000's</th>\n",
       "      <th>x3_2010's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>16.432330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>16.660205</td>\n",
       "      <td>13.878913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.392317</td>\n",
       "      <td>19.866819</td>\n",
       "      <td>17.585777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>15.904094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>17.421777</td>\n",
       "      <td>15.920004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.683653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.783612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.156320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_NumberofBuildings  log_NumberofFloors  log_PropertyGFATotal  \\\n",
       "0                       1.0            3.700440             16.432330   \n",
       "1                       1.0            3.584963             16.660205   \n",
       "2                       1.0            5.392317             19.866819   \n",
       "3                       1.0            3.459432             15.904094   \n",
       "4                       1.0            4.247928             17.421777   \n",
       "...                     ...                 ...                   ...   \n",
       "1542                    1.0            1.000000             14.156557   \n",
       "1543                    1.0            1.000000             13.965874   \n",
       "1544                    1.0            1.000000             13.683653   \n",
       "1545                    1.0            1.000000             13.783612   \n",
       "1546                    1.0            1.000000             14.156320   \n",
       "\n",
       "      log_PropertyGFAParking  x0_Campus  x0_NonResidential  \\\n",
       "0                   0.000000        0.0                1.0   \n",
       "1                  13.878913        0.0                1.0   \n",
       "2                  17.585777        0.0                1.0   \n",
       "3                   0.000000        0.0                1.0   \n",
       "4                  15.920004        0.0                1.0   \n",
       "...                      ...        ...                ...   \n",
       "1542                0.000000        0.0                0.0   \n",
       "1543                0.000000        0.0                0.0   \n",
       "1544                0.000000        0.0                0.0   \n",
       "1545                0.000000        0.0                0.0   \n",
       "1546                0.000000        0.0                0.0   \n",
       "\n",
       "      x0_Nonresidential COS  x0_Nonresidential WA  x0_SPS-District K-12  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "1542                    1.0                   0.0                   0.0   \n",
       "1543                    1.0                   0.0                   0.0   \n",
       "1544                    1.0                   0.0                   0.0   \n",
       "1545                    1.0                   0.0                   0.0   \n",
       "1546                    1.0                   0.0                   0.0   \n",
       "\n",
       "      x1_Distribution Center  ...  x3_1920's  x3_1930's  x3_1940's  x3_1950's  \\\n",
       "0                        0.0  ...        1.0        0.0        0.0        0.0   \n",
       "1                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "3                        0.0  ...        1.0        0.0        0.0        0.0   \n",
       "4                        0.0  ...        0.0        0.0        0.0        0.0   \n",
       "...                      ...  ...        ...        ...        ...        ...   \n",
       "1542                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1543                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1544                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1545                     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1546                     0.0  ...        0.0        1.0        0.0        0.0   \n",
       "\n",
       "      x3_1960's  x3_1970's  x3_1980's  x3_1990's  x3_2000's  x3_2010's  \n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1           0.0        0.0        0.0        1.0        0.0        0.0  \n",
       "2           1.0        0.0        0.0        0.0        0.0        0.0  \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "4           0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "1542        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1543        0.0        0.0        0.0        0.0        1.0        0.0  \n",
       "1544        0.0        1.0        0.0        0.0        0.0        0.0  \n",
       "1545        0.0        0.0        1.0        0.0        0.0        0.0  \n",
       "1546        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[1547 rows x 55 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe des Features, on retire les colonnes targets\n",
    "model_3_data=data.copy()\n",
    "targets=['log_SiteEnergyUse(kBtu)','log_TotalGHGEmissions']\n",
    "model_3_data.drop(targets,axis=1, inplace=True)\n",
    "model_3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12e5f504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 55)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Récupération des valeurs des features\n",
    "X_3=model_3_data.values\n",
    "X_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a328e353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04246324,  1.80319003,  0.35194475, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324,  1.68388254,  0.51427078, ...,  3.0405646 ,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324,  3.55118577,  2.79849165, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       ...,\n",
       "       [-0.04246324, -0.9868208 , -1.60606654, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324, -0.9868208 , -1.53486067, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224],\n",
       "       [-0.04246324, -0.9868208 , -1.26936336, ..., -0.32888629,\n",
       "        -0.33607981, -0.17701224]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardisation des données avec StandardScaler()\n",
    "std_scale = preprocessing.StandardScaler()\n",
    "X_3= std_scale.fit_transform(X)\n",
    "X_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a1c34fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement X_train : (1237, 55)\n",
      "Taille du jeu de test X_test: (310, 55)\n",
      "Taille de y_train : (1237,)\n",
      "Taille de y_test : (310,)\n"
     ]
    }
   ],
   "source": [
    "# Split du jeu de données en données d'entraînement et données de test\n",
    "#X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, shuffle=False) # 20% des données dans le jeu de test\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = model_selection.train_test_split(X_3, y_3, test_size=0.2,random_state=42) # 20% des données dans le jeu de test\n",
    "print(\"Taille du jeu d'entraînement X_train : \"+ str(X_train_3.shape))\n",
    "print(\"Taille du jeu de test X_test: \"+ str(X_test_3.shape))\n",
    "print(\"Taille de y_train : \"+ str(y_train_3.shape))\n",
    "print(\"Taille de y_test : \"+ str(y_test_3.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf30f6",
   "metadata": {},
   "source": [
    "## 3.2 ELastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8eee20e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.794e+02, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.017e+02, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.965e+02, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.037e+02, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.249e+02, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.578e+02, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.548e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+02, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+02, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+02, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.355e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.817e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.942e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.422e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.067e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.086e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.817e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.037e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.790e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.650e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.066e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.662e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+02, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.622e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.725e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+02, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.910e+01, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.335e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.820e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+01, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+01, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.803e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.146e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.692e+01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e+01, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.020e+01, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.806e+02, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.029e+02, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.976e+02, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.049e+02, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.262e+02, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.375e+00, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.477e+00, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.032e+00, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+01, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.733e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.784e-01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+00, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.895e+00, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.714e+00, tolerance: 4.368e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.711e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.982e-01, tolerance: 4.296e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.652e-01, tolerance: 4.225e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.889e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.242e+00, tolerance: 4.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.585e-01, tolerance: 4.353e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.925e+02, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.149e+02, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.089e+02, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.168e+02, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.385e+02, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.917e+02, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+03, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+03, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e+03, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.414e+02, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+03, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+03, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+03, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+03, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+03, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+03, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+03, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+03, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+03, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+03, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+03, tolerance: 4.353e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+03, tolerance: 4.296e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+03, tolerance: 4.225e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+03, tolerance: 4.368e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Léa Zadikian\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+03, tolerance: 4.249e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'l1_ratio': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef de régularisation. Si égale à 0, équivaut à régresison linéaire simple\n",
    "              \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}#L1 ratio , si égal à 1 équivaut à un Lasso, si égal 0 à un Ridge\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "elastic_net_grid_3 = model_selection.GridSearchCV(estimator = linear_model.ElasticNet(),  # ElasticNet regression\n",
    "                      param_grid = parameters,  # hyperparamètres à tester\n",
    "                    scoring = score,  # score à optimiser R2\n",
    "\n",
    "                      #scoring = 'neg_root_mean_squared_error',  # score à optimiserRMSE\n",
    "                      cv=5, # nombre de folds de validation croisée\n",
    "                      verbose=0\n",
    "                     )\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "elastic_net_grid_3.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fa9fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'l1_ratio': 0.9}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage les hyperparamètres optimaux\n",
    "print(\"Les meilleurs hyperparamètres pour le modèle de regression linéaire Elastic Net :\")\n",
    "elastic_net_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c18c1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs paramètres\n",
    "y_el_net_pred_3=elastic_net_grid.predict(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f59f520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.33\n",
      "R2 test : 0.58\n",
      "R2 train : 0.5463939154343668\n",
      "Temps d'execution :0.012085217748369487 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Elastic Net sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_3, y_el_net_pred_3)) ))\n",
    "print(\"R2 test : {:.2f}\".format(elastic_net_grid.score(X_test_3,y_test_3) ))\n",
    "print(\"R2 train : \" + str(elastic_net_grid_3.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (elastic_net_grid_3.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae26178",
   "metadata": {},
   "source": [
    "## 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "763e84e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=10;, score=0.495 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=10;, score=0.540 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=10;, score=0.397 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=10;, score=0.394 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=10;, score=0.415 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=50;, score=0.468 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=50;, score=0.536 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=50;, score=0.424 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=50;, score=0.482 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=50;, score=0.475 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=100;, score=0.491 total time=   0.2s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=100;, score=0.540 total time=   0.2s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=100;, score=0.451 total time=   0.2s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=100;, score=0.487 total time=   0.2s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=100;, score=0.484 total time=   0.2s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=300;, score=0.487 total time=   0.9s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=300;, score=0.544 total time=   0.9s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=300;, score=0.447 total time=   0.9s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=300;, score=0.479 total time=   0.9s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=300;, score=0.493 total time=   0.9s\n",
      "[CV 1/5] END min_samples_leaf=1, n_estimators=500;, score=0.487 total time=   1.6s\n",
      "[CV 2/5] END min_samples_leaf=1, n_estimators=500;, score=0.545 total time=   1.6s\n",
      "[CV 3/5] END min_samples_leaf=1, n_estimators=500;, score=0.450 total time=   1.6s\n",
      "[CV 4/5] END min_samples_leaf=1, n_estimators=500;, score=0.482 total time=   1.5s\n",
      "[CV 5/5] END min_samples_leaf=1, n_estimators=500;, score=0.493 total time=   1.5s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=10;, score=0.481 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=10;, score=0.530 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=10;, score=0.431 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=10;, score=0.464 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=10;, score=0.457 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=50;, score=0.482 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=50;, score=0.553 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=50;, score=0.470 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=50;, score=0.474 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=50;, score=0.505 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=100;, score=0.507 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=100;, score=0.549 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=100;, score=0.474 total time=   0.2s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=100;, score=0.474 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=100;, score=0.511 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=300;, score=0.502 total time=   0.6s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=300;, score=0.557 total time=   0.6s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=300;, score=0.472 total time=   0.6s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=300;, score=0.472 total time=   0.6s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=300;, score=0.514 total time=   0.6s\n",
      "[CV 1/5] END min_samples_leaf=3, n_estimators=500;, score=0.501 total time=   1.1s\n",
      "[CV 2/5] END min_samples_leaf=3, n_estimators=500;, score=0.557 total time=   1.1s\n",
      "[CV 3/5] END min_samples_leaf=3, n_estimators=500;, score=0.468 total time=   1.1s\n",
      "[CV 4/5] END min_samples_leaf=3, n_estimators=500;, score=0.475 total time=   1.1s\n",
      "[CV 5/5] END min_samples_leaf=3, n_estimators=500;, score=0.521 total time=   1.1s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=10;, score=0.492 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=10;, score=0.527 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=10;, score=0.452 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=10;, score=0.437 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=10;, score=0.498 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=50;, score=0.512 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=50;, score=0.555 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=50;, score=0.482 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=50;, score=0.447 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=50;, score=0.508 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=100;, score=0.502 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=100;, score=0.555 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=100;, score=0.482 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=100;, score=0.466 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=100;, score=0.516 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=300;, score=0.510 total time=   0.6s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=300;, score=0.552 total time=   0.6s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=300;, score=0.489 total time=   0.6s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=300;, score=0.465 total time=   0.5s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=300;, score=0.514 total time=   0.5s\n",
      "[CV 1/5] END min_samples_leaf=5, n_estimators=500;, score=0.508 total time=   1.0s\n",
      "[CV 2/5] END min_samples_leaf=5, n_estimators=500;, score=0.560 total time=   1.0s\n",
      "[CV 3/5] END min_samples_leaf=5, n_estimators=500;, score=0.489 total time=   1.0s\n",
      "[CV 4/5] END min_samples_leaf=5, n_estimators=500;, score=0.466 total time=   1.0s\n",
      "[CV 5/5] END min_samples_leaf=5, n_estimators=500;, score=0.523 total time=   1.0s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=10;, score=0.513 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=10;, score=0.498 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=10;, score=0.462 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=10;, score=0.425 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=10;, score=0.484 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=50;, score=0.503 total time=   0.0s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=50;, score=0.518 total time=   0.0s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=50;, score=0.486 total time=   0.0s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=50;, score=0.429 total time=   0.0s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=50;, score=0.485 total time=   0.0s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=100;, score=0.502 total time=   0.1s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=100;, score=0.520 total time=   0.1s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=100;, score=0.480 total time=   0.1s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=100;, score=0.445 total time=   0.1s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=100;, score=0.494 total time=   0.1s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=300;, score=0.506 total time=   0.4s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=300;, score=0.514 total time=   0.4s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=300;, score=0.488 total time=   0.4s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=300;, score=0.437 total time=   0.4s\n",
      "[CV 5/5] END min_samples_leaf=10, n_estimators=300;, score=0.494 total time=   0.4s\n",
      "[CV 1/5] END min_samples_leaf=10, n_estimators=500;, score=0.506 total time=   0.8s\n",
      "[CV 2/5] END min_samples_leaf=10, n_estimators=500;, score=0.515 total time=   0.8s\n",
      "[CV 3/5] END min_samples_leaf=10, n_estimators=500;, score=0.487 total time=   0.8s\n",
      "[CV 4/5] END min_samples_leaf=10, n_estimators=500;, score=0.438 total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END min_samples_leaf=10, n_estimators=500;, score=0.490 total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;min_samples_leaf&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100, 300, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'min_samples_leaf': [1, 3, 5, 10],\n",
       "                         'n_estimators': [10, 50, 100, 300, 500]},\n",
       "             scoring='r2', verbose=5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On fixe les valeurs des hyperparamètres à tester\n",
    "parameters = {\n",
    "    'n_estimators' : [10,50,100,300,500], #nombre d'arbres de décision\n",
    "    'min_samples_leaf' : [1,3,5,10], #nombre de feuilles minimales dans un noeud\n",
    "    #'max_features': ['auto', 'sqrt'] #nombre de features observées pour chaque arbre\n",
    "}\n",
    "\n",
    "\n",
    "# On choisit un score à optimiser, ici R2\n",
    "score = 'r2'\n",
    "\n",
    "#On crée une grille avec recherche d'hyperparamètres par validation croisée\n",
    "\n",
    "random_forest_grid_3 = model_selection.GridSearchCV(RandomForestRegressor(),\n",
    "                               param_grid = parameters,\n",
    "                               scoring=score,\n",
    "                              verbose=5,\n",
    "                               cv=5)\n",
    "\n",
    "# Optimisation sur le jeu d'entraînement\n",
    "random_forest_grid_3.fit(X_train_3, y_train_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c64d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les Meilleurs hyperparamètres pour le modèle non linéaire Random Forest \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 5, 'n_estimators': 500}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les hyperparamètres optimaux\n",
    "print(\"Les Meilleurs hyperparamètres pour le modèle non linéaire Random Forest \")\n",
    "random_forest_grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9c95917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prédiction sur le jeu de test avec les meilleurs parametres\n",
    "y_rand_for_pred_3 = random_forest_grid_3.predict(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5018d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.50\n",
      "R2 : 0.47\n",
      "R2 : 0.5091792586514681\n",
      "Temps d'execution :0.45692919254302977 s\n"
     ]
    }
   ],
   "source": [
    "# Evaluation du modèle Random Forest sur le jeu de test avec les meilleurs hyperparametres\n",
    "print(\"RMSE : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test_3, y_rand_for_pred_3)) ))\n",
    "print(\"R2 : {:.2f}\".format(random_forest_grid_3.score(X_test_3,y_test_3) ))\n",
    "print(\"R2 : \"+ str(random_forest_grid_3.best_score_))\n",
    "print(\"Temps d'execution :\"+ str (random_forest_grid_3.cv_results_['mean_fit_time'].mean())+ \" s\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
